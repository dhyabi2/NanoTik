{"file_contents":{"README.md":{"content":"# ðŸŽ¬ NanoTik - AI Video Generator\n\n**Enhanced MoneyPrinterTurbo with Nano Cryptocurrency Payments**\n\nNanoTik is an AI-powered video generator that creates professional videos from simple text prompts, with integrated Nano cryptocurrency payment system.\n\n## âœ¨ Features\n\n- ðŸ¤– **AI-Powered Video Generation** - Create professional videos from text prompts\n- ðŸ’° **Nano Payments** - Instant, fee-less cryptocurrency transactions\n- ðŸŒ **Multi-Language Support** - English, Chinese (ç®€ä½“ä¸­æ–‡), and Arabic (Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)\n- ðŸ“± **Responsive Design** - Works on all devices and screen sizes\n- ðŸŽ¨ **Modern UI** - Beautiful Streamlit interface with professional styling\n\n## ðŸš€ Quick Start\n\n### Prerequisites\n\n- Python 3.9 or higher\n- Required API keys (see Configuration section)\n\n### Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/dhyabi2/NanoTik.git\ncd NanoTik\n","size_bytes":901},"app.py":{"content":"import sys\nimport os\n\nsys.path.insert(0, os.path.dirname(__file__))\n\nexec(open('webui/NanoTik.py').read())\n","size_bytes":107},"config.example.toml":{"content":"# NanoTik Configuration File\n# Copy this file to config.toml and fill in your API keys\n\n[app]\n# LLM Provider Selection\n# Options: \"openai\", \"deepseek\", \"moonshot\"\nllm_provider = \"openai\"\n\n# OpenAI Configuration\nopenai_api_key = \"\"\nopenai_base_url = \"https://api.openai.com/v1\"\nopenai_model_name = \"gpt-4\"\n\n# DeepSeek Configuration\ndeepseek_api_key = \"\"\n\n# Moonshot Configuration\nmoonshot_api_key = \"\"\n\n# Video Source API Keys\npexels_api_keys = []\npixabay_api_keys = []\n\n[azure]\n# Azure Speech Services\nspeech_key = \"\"\nspeech_region = \"eastus\"\n\n[video]\n# Video Generation Settings\noutput_dir = \"./output\"\ntemp_dir = \"./temp\"\nmax_duration = 180\ndefault_resolution = \"1920x1080\"\n\n[payment]\n# Nano Payment Configuration\nnano_mcp_url = \"https://nano-mcp.replit.app\"\nnano_wallet_address = \"\"\n","size_bytes":786},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"azure-cognitiveservices-speech>=1.46.0\",\n    \"imageio>=2.37.0\",\n    \"imageio-ffmpeg>=0.6.0\",\n    \"moviepy>=2.2.1\",\n    \"numpy>=2.3.3\",\n    \"openai>=2.0.0\",\n    \"pexels-api>=1.0.1\",\n    \"pillow>=11.3.0\",\n    \"psycopg2-binary>=2.9.10\",\n    \"requests>=2.32.5\",\n    \"sqlalchemy>=2.0.43\",\n    \"streamlit>=1.50.0\",\n    \"toml>=0.10.2\",\n]\n","size_bytes":478},"replit.md":{"content":"# NanoTik - AI Video Generator\n\n## Overview\n\nNanoTik is an AI-powered video generation platform that creates professional videos from text prompts, integrated with Nano cryptocurrency payments. The application combines multiple AI services (LLM for script generation, Azure Speech for voiceovers, Pexels for video clips) with a cryptocurrency payment system to deliver a complete video production solution. Built with Python and Streamlit, it offers a multi-language web interface supporting English, Chinese, and Arabic.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## System Architecture\n\n### Frontend Architecture\n- **Framework**: Streamlit web application with responsive design\n- **UI Components**: Wide layout with expandable sidebar for navigation and payment controls\n- **State Management**: Streamlit session state for user sessions, credits, language preferences, and transaction history\n- **Internationalization**: Custom i18n utility supporting 3 languages (English, Chinese, Arabic) with translation dictionaries\n\n**Rationale**: Streamlit provides rapid development of data-driven applications with minimal frontend code. The session state approach keeps user data persistent across interactions without requiring complex state management libraries.\n\n### Backend Architecture\n- **Application Structure**: Modular service-oriented architecture with separated concerns:\n  - `services/`: Business logic (LLM, Payment, Video services)\n  - `models/`: Data models (UserSession)\n  - `utils/`: Helper functions (i18n)\n- **Configuration**: TOML-based config with environment variable overrides (priority: env vars > config.toml > config.example.toml)\n- **Video Processing Pipeline**: Multi-stage workflow:\n  1. Script generation via LLM\n  2. Voiceover synthesis with Azure Speech\n  3. Video clip sourcing from Pexels\n  4. Final composition with MoviePy\n\n**Rationale**: Service-oriented design allows independent scaling and testing of components. The pipeline architecture enables monitoring and failure recovery at each stage of video generation.\n\n### Data Storage\n- **Database**: PostgreSQL with psycopg2 driver\n- **Schema Design**:\n  - `users`: Tracks user sessions, credits, and activity timestamps\n  - `videos`: Stores generated video metadata with foreign key to users\n- **Connection Pattern**: Context manager pattern for automatic connection cleanup\n- **Initialization**: Automatic table creation on first database connection\n\n**Rationale**: PostgreSQL provides ACID compliance for payment and credit transactions. The foreign key relationship ensures referential integrity between users and their videos.\n\n### Authentication & Authorization\n- **Session Management**: UUID-based session IDs stored in Streamlit session state\n- **User Tracking**: Anonymous sessions linked to database users via session_id\n- **Credit System**: Integer-based credits stored in database, checked before video generation\n\n**Rationale**: Anonymous session approach eliminates registration friction while maintaining user state. Database-backed credits ensure consistency even if session state is lost.\n\n### AI/LLM Integration\n- **Multi-Provider Support**: Pluggable LLM architecture supporting:\n  - OpenAI (GPT-4)\n  - DeepSeek\n  - Moonshot AI\n- **Provider Selection**: Configuration-driven provider switching via environment variables\n- **Client Initialization**: Unified OpenAI client interface with provider-specific base URLs\n\n**Rationale**: Multi-provider approach prevents vendor lock-in and allows cost optimization by switching between providers based on pricing and availability.\n\n### Video Generation Architecture\n- **Script Generation**: LLM service creates structured scripts based on topic and duration\n- **Voiceover Synthesis**: Azure Cognitive Services Speech SDK for text-to-speech\n- **Video Sourcing**: Pexels API integration for stock video clips\n- **Composition**: MoviePy for video editing, effects, and final rendering\n- **Quality Tiers**: Three-tier system (Basic/HD/Premium) with different credit costs\n\n**Rationale**: Azure Speech provides high-quality multilingual voices. Pexels offers free stock footage. MoviePy enables programmatic video editing without external dependencies.\n\n### Payment System\n- **Cryptocurrency**: Nano cryptocurrency for instant, fee-less transactions\n- **Payment Flow**: UUID-based payment requests with address generation\n- **Credit Conversion**: Direct mapping of NANO amounts to credit values\n- **Transaction Tracking**: Payment IDs linked to user sessions for audit trail\n\n**Rationale**: Nano eliminates transaction fees and provides instant settlement, crucial for micropayments. The simulated payment flow structure allows easy integration with actual Nano MCP server.\n\n## External Dependencies\n\n### Third-Party APIs\n- **OpenAI API**: LLM for script generation (supports custom base URLs for compatible providers)\n- **DeepSeek API**: Alternative LLM provider (base URL: https://api.deepseek.com/v1)\n- **Moonshot API**: Alternative LLM provider (base URL: https://api.moonshot.cn/v1)\n- **Azure Cognitive Services**: Speech synthesis API (configurable region)\n- **Pexels API**: Stock video footage (supports multiple API keys for rate limiting)\n- **Nano MCP Server**: Cryptocurrency payment processing (environment: NANO_MCP_URL)\n\n### Python Libraries\n- **streamlit**: Web application framework\n- **psycopg2**: PostgreSQL database driver with RealDictCursor support\n- **openai**: Unified client for multiple LLM providers\n- **azure-cognitiveservices-speech**: Azure Speech SDK\n- **pexels-api**: Pexels video search client\n- **moviepy**: Video editing and composition\n- **toml**: Configuration file parsing\n\n### Database\n- **PostgreSQL**: Primary data store accessed via DATABASE_URL environment variable\n- **Schema**: Auto-created tables for users and videos with timestamp tracking\n- **Connection Pooling**: Not implemented (uses direct connections with context managers)\n\n### Environment Configuration\n- Required environment variables:\n  - `DATABASE_URL`: PostgreSQL connection string\n  - `OPENAI_API_KEY`, `DEEPSEEK_API_KEY`, `MOONSHOT_API_KEY`: LLM provider keys\n  - `AZURE_SPEECH_KEY`, `AZURE_SPEECH_REGION`: Azure Speech credentials\n  - `PEXELS_API_KEYS`: Comma-separated list of Pexels API keys\n  - `NANO_MCP_URL`, `NANO_WALLET_ADDRESS`: Nano payment configuration\n  - `LLM_PROVIDER`: Provider selection (openai/deepseek/moonshot)\n\n### File System Dependencies\n- **Output Directories**: Configurable paths for generated videos and temporary files\n- **Video Storage**: Local filesystem storage with path references in database\n- **Temp Files**: Automatic cleanup not implemented (manual temp directory management)","size_bytes":6700},"app/__init__.py":{"content":"\"\"\"\nNanoTik Application Package\n\"\"\"\n\n__version__ = \"1.0.0\"\n__author__ = \"NanoTik Team\"\n","size_bytes":87},"app/config.py":{"content":"\"\"\"\nConfiguration management for NanoTik\nLoads settings from environment variables and config files\n\"\"\"\n\nimport os\nimport toml\nfrom pathlib import Path\nfrom typing import Dict, Any\n\n\ndef load_config() -> Dict[str, Any]:\n    \"\"\"\n    Load configuration from environment variables and config file\n    Priority: Environment variables > config.toml > config.example.toml\n    \"\"\"\n    config = {}\n    \n    # Try to load from config.toml first\n    config_path = Path('config.toml')\n    example_config_path = Path('config.example.toml')\n    \n    if config_path.exists():\n        with open(config_path, 'r', encoding='utf-8') as f:\n            config = toml.load(f)\n    elif example_config_path.exists():\n        with open(example_config_path, 'r', encoding='utf-8') as f:\n            config = toml.load(f)\n    \n    # Override with environment variables\n    config['app'] = config.get('app', {})\n    config['azure'] = config.get('azure', {})\n    config['video'] = config.get('video', {})\n    config['payment'] = config.get('payment', {})\n    \n    # LLM Configuration\n    config['app']['llm_provider'] = os.getenv('LLM_PROVIDER', config['app'].get('llm_provider', 'openai'))\n    config['app']['openai_api_key'] = os.getenv('OPENAI_API_KEY', config['app'].get('openai_api_key', ''))\n    config['app']['deepseek_api_key'] = os.getenv('DEEPSEEK_API_KEY', config['app'].get('deepseek_api_key', ''))\n    config['app']['moonshot_api_key'] = os.getenv('MOONSHOT_API_KEY', config['app'].get('moonshot_api_key', ''))\n    config['app']['openai_base_url'] = os.getenv('OPENAI_BASE_URL', config['app'].get('openai_base_url', 'https://api.openai.com/v1'))\n    config['app']['openai_model_name'] = os.getenv('OPENAI_MODEL_NAME', config['app'].get('openai_model_name', 'gpt-4'))\n    \n    # Azure Speech Configuration\n    config['azure']['speech_key'] = os.getenv('AZURE_SPEECH_KEY', config['azure'].get('speech_key', ''))\n    config['azure']['speech_region'] = os.getenv('AZURE_SPEECH_REGION', config['azure'].get('speech_region', 'eastus'))\n    \n    # Video Source Configuration\n    pexels_keys = os.getenv('PEXELS_API_KEYS', '')\n    if pexels_keys:\n        config['app']['pexels_api_keys'] = pexels_keys.split(',')\n    else:\n        config['app']['pexels_api_keys'] = config['app'].get('pexels_api_keys', [])\n    \n    pixabay_keys = os.getenv('PIXABAY_API_KEYS', '')\n    if pixabay_keys:\n        config['app']['pixabay_api_keys'] = pixabay_keys.split(',')\n    else:\n        config['app']['pixabay_api_keys'] = config['app'].get('pixabay_api_keys', [])\n    \n    # Payment Configuration\n    config['payment']['nano_mcp_url'] = os.getenv('NANO_MCP_URL', config['payment'].get('nano_mcp_url', 'https://nano-mcp.replit.app'))\n    config['payment']['nano_wallet_address'] = os.getenv('NANO_WALLET_ADDRESS', config['payment'].get('nano_wallet_address', ''))\n    \n    # Video Configuration\n    config['video']['output_dir'] = os.getenv('VIDEO_OUTPUT_DIR', config['video'].get('output_dir', './output'))\n    config['video']['temp_dir'] = os.getenv('VIDEO_TEMP_DIR', config['video'].get('temp_dir', './temp'))\n    config['video']['max_duration'] = int(os.getenv('VIDEO_MAX_DURATION', config['video'].get('max_duration', 180)))\n    config['video']['default_resolution'] = os.getenv('VIDEO_DEFAULT_RESOLUTION', config['video'].get('default_resolution', '1920x1080'))\n    \n    return config\n\n\ndef get_config_value(key: str, default: Any = None) -> Any:\n    \"\"\"\n    Get a configuration value by key with dot notation\n    Example: get_config_value('app.openai_api_key')\n    \"\"\"\n    config = load_config()\n    keys = key.split('.')\n    value = config\n    \n    for k in keys:\n        if isinstance(value, dict):\n            value = value.get(k)\n        else:\n            return default\n    \n    return value if value is not None else default\n\n\ndef validate_config() -> tuple[bool, list[str]]:\n    \"\"\"\n    Validate that required configuration is present\n    Returns: (is_valid, list_of_errors)\n    \"\"\"\n    config = load_config()\n    errors = []\n    \n    # Check LLM API keys\n    llm_provider = config['app'].get('llm_provider', 'openai')\n    if llm_provider == 'openai' and not config['app'].get('openai_api_key'):\n        errors.append(\"OpenAI API key is required when using OpenAI as LLM provider\")\n    elif llm_provider == 'deepseek' and not config['app'].get('deepseek_api_key'):\n        errors.append(\"DeepSeek API key is required when using DeepSeek as LLM provider\")\n    \n    # Check video source API keys\n    if not config['app'].get('pexels_api_keys') and not config['app'].get('pixabay_api_keys'):\n        errors.append(\"At least one video source API key (Pexels or Pixabay) is required\")\n    \n    # Check Azure Speech key for voice synthesis\n    if not config['azure'].get('speech_key'):\n        errors.append(\"Azure Speech API key is required for voice synthesis\")\n    \n    return len(errors) == 0, errors\n","size_bytes":4876},"app/database.py":{"content":"\"\"\"\nDatabase module for NanoTik\nHandles PostgreSQL connections and operations\n\"\"\"\n\nimport os\nimport psycopg2\nfrom psycopg2.extras import RealDictCursor\nfrom typing import Dict, Any, List, Optional\nfrom datetime import datetime\nimport uuid\n\n\nclass Database:\n    \"\"\"Database connection and operations manager\"\"\"\n    \n    def __init__(self):\n        self.database_url = os.getenv('DATABASE_URL')\n        if not self.database_url:\n            raise Exception(\"DATABASE_URL not configured\")\n        self._ensure_tables()\n    \n    def get_connection(self):\n        \"\"\"Get a database connection\"\"\"\n        return psycopg2.connect(self.database_url)\n    \n    def _ensure_tables(self):\n        \"\"\"Create tables if they don't exist\"\"\"\n        with self.get_connection() as conn:\n            with conn.cursor() as cur:\n                # Users table\n                cur.execute(\"\"\"\n                    CREATE TABLE IF NOT EXISTS users (\n                        id VARCHAR(36) PRIMARY KEY,\n                        session_id VARCHAR(36) UNIQUE NOT NULL,\n                        credits INTEGER DEFAULT 0,\n                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                        last_active TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n                    )\n                \"\"\")\n                \n                # Videos table\n                cur.execute(\"\"\"\n                    CREATE TABLE IF NOT EXISTS videos (\n                        id VARCHAR(36) PRIMARY KEY,\n                        user_id VARCHAR(36) REFERENCES users(id),\n                        title VARCHAR(255) NOT NULL,\n                        topic TEXT NOT NULL,\n                        file_path TEXT NOT NULL,\n                        duration INTEGER,\n                        quality VARCHAR(50),\n                        language VARCHAR(10),\n                        status VARCHAR(50) DEFAULT 'completed',\n                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n                    )\n                \"\"\")\n                \n                # Transactions table\n                cur.execute(\"\"\"\n                    CREATE TABLE IF NOT EXISTS transactions (\n                        id VARCHAR(36) PRIMARY KEY,\n                        user_id VARCHAR(36) REFERENCES users(id),\n                        transaction_type VARCHAR(50) NOT NULL,\n                        amount NUMERIC(38, 18),\n                        credits INTEGER NOT NULL,\n                        currency VARCHAR(10),\n                        payment_id VARCHAR(100) UNIQUE,\n                        status VARCHAR(50) DEFAULT 'pending',\n                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                        completed_at TIMESTAMP\n                    )\n                \"\"\")\n                \n                # Create indexes for better query performance\n                cur.execute(\"\"\"\n                    CREATE INDEX IF NOT EXISTS idx_videos_user_id ON videos(user_id)\n                \"\"\")\n                cur.execute(\"\"\"\n                    CREATE INDEX IF NOT EXISTS idx_transactions_user_id ON transactions(user_id)\n                \"\"\")\n                cur.execute(\"\"\"\n                    CREATE INDEX IF NOT EXISTS idx_transactions_payment_id ON transactions(payment_id)\n                \"\"\")\n                \n                conn.commit()\n    \n    def create_user(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Create a new user\"\"\"\n        user_id = str(uuid.uuid4())\n        \n        with self.get_connection() as conn:\n            with conn.cursor(cursor_factory=RealDictCursor) as cur:\n                cur.execute(\"\"\"\n                    INSERT INTO users (id, session_id, credits)\n                    VALUES (%s, %s, 0)\n                    RETURNING *\n                \"\"\", (user_id, session_id))\n                \n                conn.commit()\n                return dict(cur.fetchone())\n    \n    def get_user_by_session(self, session_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Get user by session ID\"\"\"\n        with self.get_connection() as conn:\n            with conn.cursor(cursor_factory=RealDictCursor) as cur:\n                cur.execute(\"\"\"\n                    SELECT * FROM users WHERE session_id = %s\n                \"\"\", (session_id,))\n                \n                result = cur.fetchone()\n                return dict(result) if result else None\n    \n    def update_user_credits(self, user_id: str, credits: int) -> bool:\n        \"\"\"Update user's credit balance\"\"\"\n        with self.get_connection() as conn:\n            with conn.cursor() as cur:\n                cur.execute(\"\"\"\n                    UPDATE users SET credits = %s, last_active = CURRENT_TIMESTAMP\n                    WHERE id = %s\n                \"\"\", (credits, user_id))\n                \n                conn.commit()\n                return cur.rowcount > 0\n    \n    def add_credits(self, user_id: str, amount: int) -> int:\n        \"\"\"Add credits to user and return new balance\"\"\"\n        with self.get_connection() as conn:\n            with conn.cursor() as cur:\n                cur.execute(\"\"\"\n                    UPDATE users SET credits = credits + %s, last_active = CURRENT_TIMESTAMP\n                    WHERE id = %s\n                    RETURNING credits\n                \"\"\", (amount, user_id))\n                \n                conn.commit()\n                result = cur.fetchone()\n                return result[0] if result else 0\n    \n    def deduct_credits(self, user_id: str, amount: int) -> bool:\n        \"\"\"Deduct credits from user if sufficient balance\"\"\"\n        with self.get_connection() as conn:\n            with conn.cursor() as cur:\n                cur.execute(\"\"\"\n                    UPDATE users SET credits = credits - %s, last_active = CURRENT_TIMESTAMP\n                    WHERE id = %s AND credits >= %s\n                    RETURNING credits\n                \"\"\", (amount, user_id, amount))\n                \n                conn.commit()\n                return cur.rowcount > 0\n    \n    def create_video(self, user_id: str, video_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Create a video record\"\"\"\n        video_id = str(uuid.uuid4())\n        \n        with self.get_connection() as conn:\n            with conn.cursor(cursor_factory=RealDictCursor) as cur:\n                cur.execute(\"\"\"\n                    INSERT INTO videos (id, user_id, title, topic, file_path, duration, quality, language, status)\n                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n                    RETURNING *\n                \"\"\", (\n                    video_id,\n                    user_id,\n                    video_data.get('title', ''),\n                    video_data.get('topic', ''),\n                    video_data.get('file_path', ''),\n                    video_data.get('duration', 0),\n                    video_data.get('quality', 'basic'),\n                    video_data.get('language', 'en'),\n                    video_data.get('status', 'completed')\n                ))\n                \n                conn.commit()\n                return dict(cur.fetchone())\n    \n    def get_user_videos(self, user_id: str, limit: int = 50) -> List[Dict[str, Any]]:\n        \"\"\"Get all videos for a user\"\"\"\n        with self.get_connection() as conn:\n            with conn.cursor(cursor_factory=RealDictCursor) as cur:\n                cur.execute(\"\"\"\n                    SELECT * FROM videos\n                    WHERE user_id = %s\n                    ORDER BY created_at DESC\n                    LIMIT %s\n                \"\"\", (user_id, limit))\n                \n                return [dict(row) for row in cur.fetchall()]\n    \n    def create_transaction(self, user_id: str, transaction_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Create a transaction record\"\"\"\n        transaction_id = str(uuid.uuid4())\n        \n        with self.get_connection() as conn:\n            with conn.cursor(cursor_factory=RealDictCursor) as cur:\n                cur.execute(\"\"\"\n                    INSERT INTO transactions (id, user_id, transaction_type, amount, credits, currency, payment_id, status)\n                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n                    RETURNING *\n                \"\"\", (\n                    transaction_id,\n                    user_id,\n                    transaction_data.get('transaction_type', 'purchase'),\n                    transaction_data.get('amount', 0),\n                    transaction_data.get('credits', 0),\n                    transaction_data.get('currency', 'NANO'),\n                    transaction_data.get('payment_id', ''),\n                    transaction_data.get('status', 'pending')\n                ))\n                \n                conn.commit()\n                return dict(cur.fetchone())\n    \n    def update_transaction_status(self, transaction_id: str, status: str) -> bool:\n        \"\"\"Update transaction status\"\"\"\n        with self.get_connection() as conn:\n            with conn.cursor() as cur:\n                cur.execute(\"\"\"\n                    UPDATE transactions \n                    SET status = %s, completed_at = CURRENT_TIMESTAMP\n                    WHERE id = %s\n                \"\"\", (status, transaction_id))\n                \n                conn.commit()\n                return cur.rowcount > 0\n    \n    def get_user_transactions(self, user_id: str, limit: int = 50) -> List[Dict[str, Any]]:\n        \"\"\"Get transaction history for a user\"\"\"\n        with self.get_connection() as conn:\n            with conn.cursor(cursor_factory=RealDictCursor) as cur:\n                cur.execute(\"\"\"\n                    SELECT * FROM transactions\n                    WHERE user_id = %s\n                    ORDER BY created_at DESC\n                    LIMIT %s\n                \"\"\", (user_id, limit))\n                \n                return [dict(row) for row in cur.fetchall()]\n\n\n# Global database instance\n_db_instance = None\n\ndef get_database() -> Database:\n    \"\"\"Get or create the global database instance\"\"\"\n    global _db_instance\n    if _db_instance is None:\n        _db_instance = Database()\n    return _db_instance\n","size_bytes":10071},"webui/NanoTik.py":{"content":"\"\"\"\nNanoTik - AI Video Generator with Nano Cryptocurrency Payments\nEnhanced version of MoneyPrinterTurbo with modern UI and payment integration\n\"\"\"\n\nimport streamlit as st\nimport os\nimport sys\nfrom pathlib import Path\n\n# Add parent directory to path\nsys.path.insert(0, str(Path(__file__).parent.parent))\n\nfrom app.config import load_config\nfrom app.utils.i18n import get_text, set_language, SUPPORTED_LANGUAGES\nfrom app.services.payment_service import PaymentService\nfrom app.services.video_service import VideoService\nfrom app.models.user import UserSession\nfrom app.database import get_database\n\n# Page configuration\nst.set_page_config(\n    page_title=\"NanoTik - AI Video Generator\",\n    page_icon=\"ðŸŽ¬\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\"\n)\n\n# Initialize database\ndb = get_database()\n\n# Initialize session state\nif 'user_session' not in st.session_state:\n    st.session_state.user_session = UserSession()\n    # Get or create user in database\n    db_user = db.get_user_by_session(st.session_state.user_session.session_id)\n    if not db_user:\n        db_user = db.create_user(st.session_state.user_session.session_id)\n    st.session_state.user_id = db_user['id']\n    st.session_state.credits = db_user['credits']\n\nif 'language' not in st.session_state:\n    st.session_state.language = 'en'\n\nif 'credits' not in st.session_state:\n    st.session_state.credits = 0\n\n# Load configuration\nconfig = load_config()\n\n# Initialize services\npayment_service = PaymentService()\nvideo_service = VideoService(config)\n\n\ndef render_header():\n    \"\"\"Render the application header with language selector\"\"\"\n    col1, col2, col3 = st.columns([3, 1, 1])\n    \n    with col1:\n        st.title(\"ðŸŽ¬ NanoTik\")\n        st.caption(get_text('app.subtitle', st.session_state.language))\n    \n    with col2:\n        st.metric(\n            label=get_text('credits.balance', st.session_state.language),\n            value=st.session_state.credits\n        )\n    \n    with col3:\n        language = st.selectbox(\n            get_text('language.select', st.session_state.language),\n            options=list(SUPPORTED_LANGUAGES.keys()),\n            format_func=lambda x: SUPPORTED_LANGUAGES[x],\n            key='language_selector'\n        )\n        if language != st.session_state.language:\n            st.session_state.language = language\n            set_language(language)\n            st.rerun()\n\n\ndef render_sidebar():\n    \"\"\"Render the sidebar with credit packages and payment options\"\"\"\n    with st.sidebar:\n        st.header(get_text('credits.buy', st.session_state.language))\n        \n        # Credit packages\n        packages = [\n            {\"credits\": 10, \"price\": 0.1, \"bonus\": 0, \"popular\": False},\n            {\"credits\": 50, \"price\": 0.4, \"bonus\": 5, \"popular\": True},\n            {\"credits\": 100, \"price\": 0.7, \"bonus\": 15, \"popular\": False},\n            {\"credits\": 500, \"price\": 3.0, \"bonus\": 100, \"popular\": False},\n        ]\n        \n        for pkg in packages:\n            with st.container():\n                if pkg['popular']:\n                    st.markdown(\"â­ **POPULAR**\")\n                \n                col1, col2 = st.columns([2, 1])\n                with col1:\n                    total_credits = pkg['credits'] + pkg['bonus']\n                    st.write(f\"**{pkg['credits']} {get_text('credits.name', st.session_state.language)}**\")\n                    if pkg['bonus'] > 0:\n                        st.caption(f\"+{pkg['bonus']} {get_text('credits.bonus', st.session_state.language)}\")\n                \n                with col2:\n                    st.write(f\"{pkg['price']} NANO\")\n                \n                if st.button(\n                    get_text('credits.purchase', st.session_state.language),\n                    key=f\"buy_{pkg['credits']}\",\n                    use_container_width=True\n                ):\n                    handle_purchase(pkg['credits'], pkg['bonus'], pkg['price'])\n                \n                st.divider()\n        \n        # Info section\n        st.info(get_text('credits.info', st.session_state.language))\n        \n        # Cost breakdown\n        with st.expander(get_text('credits.costs', st.session_state.language)):\n            st.write(f\"- {get_text('video.basic', st.session_state.language)}: 1 {get_text('credits.name', st.session_state.language)}\")\n            st.write(f\"- {get_text('video.hd', st.session_state.language)}: 2 {get_text('credits.name', st.session_state.language)}\")\n            st.write(f\"- {get_text('video.premium', st.session_state.language)}: 3 {get_text('credits.name', st.session_state.language)}\")\n\n\ndef handle_purchase(credits, bonus, price):\n    \"\"\"Handle credit purchase with Nano payment\"\"\"\n    with st.spinner(get_text('payment.processing', st.session_state.language)):\n        try:\n            # Generate payment request\n            payment_result = payment_service.create_payment_request(\n                amount=price,\n                credits=credits + bonus,\n                user_id=st.session_state.user_id\n            )\n            \n            if payment_result['success']:\n                # Add credits to database\n                total_credits = credits + bonus\n                new_balance = db.add_credits(st.session_state.user_id, total_credits)\n                st.session_state.credits = new_balance\n                \n                st.success(get_text('payment.success', st.session_state.language))\n                st.rerun()\n            else:\n                st.error(get_text('payment.failed', st.session_state.language))\n        except Exception as e:\n            st.error(f\"{get_text('payment.error', st.session_state.language)}: {str(e)}\")\n\n\ndef render_video_generator():\n    \"\"\"Render the main video generation interface\"\"\"\n    st.header(get_text('video.generate', st.session_state.language))\n    \n    # Check credits\n    if st.session_state.credits < 1:\n        st.warning(get_text('credits.insufficient', st.session_state.language))\n        st.info(get_text('credits.buy_prompt', st.session_state.language))\n        return\n    \n    # Video generation form\n    with st.form(\"video_generator\"):\n        # Topic input\n        topic = st.text_input(\n            get_text('video.topic', st.session_state.language),\n            placeholder=get_text('video.topic_placeholder', st.session_state.language)\n        )\n        \n        col1, col2 = st.columns(2)\n        \n        with col1:\n            # Quality selection\n            quality = st.selectbox(\n                get_text('video.quality', st.session_state.language),\n                options=['basic', 'hd', 'premium'],\n                format_func=lambda x: get_text(f'video.{x}', st.session_state.language)\n            )\n        \n        with col2:\n            # Duration selection\n            duration = st.slider(\n                get_text('video.duration', st.session_state.language),\n                min_value=15,\n                max_value=180,\n                value=60,\n                step=15\n            )\n        \n        # Advanced options\n        with st.expander(get_text('video.advanced', st.session_state.language)):\n            col1, col2 = st.columns(2)\n            \n            with col1:\n                voice = st.selectbox(\n                    get_text('video.voice', st.session_state.language),\n                    options=['male', 'female', 'neutral']\n                )\n            \n            with col2:\n                music = st.checkbox(\n                    get_text('video.music', st.session_state.language),\n                    value=True\n                )\n            \n            subtitle_position = st.selectbox(\n                get_text('video.subtitle_position', st.session_state.language),\n                options=['bottom', 'top', 'center']\n            )\n        \n        # Submit button\n        submitted = st.form_submit_button(\n            get_text('video.create', st.session_state.language),\n            use_container_width=True\n        )\n        \n        if submitted:\n            if not topic:\n                st.error(get_text('video.topic_required', st.session_state.language))\n            else:\n                generate_video(topic, quality, duration, voice, music, subtitle_position)\n\n\ndef generate_video(topic, quality, duration, voice, music, subtitle_position):\n    \"\"\"Generate video based on user input\"\"\"\n    # Calculate credit cost\n    cost_map = {'basic': 1, 'hd': 2, 'premium': 3}\n    cost = cost_map[quality]\n    \n    if st.session_state.credits < cost:\n        st.error(get_text('credits.insufficient', st.session_state.language))\n        return\n    \n    # Progress tracking\n    progress_bar = st.progress(0)\n    status_text = st.empty()\n    \n    try:\n        # Step 1: Generate script\n        status_text.text(get_text('video.generating_script', st.session_state.language))\n        progress_bar.progress(20)\n        \n        script = video_service.generate_script(topic, duration, st.session_state.language)\n        \n        # Step 2: Generate voiceover\n        status_text.text(get_text('video.generating_voice', st.session_state.language))\n        progress_bar.progress(40)\n        \n        audio_path = video_service.generate_voiceover(script, voice, st.session_state.language)\n        \n        # Step 3: Search for video clips\n        status_text.text(get_text('video.searching_clips', st.session_state.language))\n        progress_bar.progress(60)\n        \n        clips = video_service.search_video_clips(script)\n        \n        # Step 4: Compose video\n        status_text.text(get_text('video.composing', st.session_state.language))\n        progress_bar.progress(80)\n        \n        video_path = video_service.compose_video(\n            clips=clips,\n            audio_path=audio_path,\n            script=script,\n            subtitle_position=subtitle_position,\n            quality=quality,\n            music=music\n        )\n        \n        # Step 5: Finalize\n        progress_bar.progress(100)\n        status_text.text(get_text('video.complete', st.session_state.language))\n        \n        # Deduct credits from database\n        if db.deduct_credits(st.session_state.user_id, cost):\n            st.session_state.credits -= cost\n            \n            # Save video to database\n            video_record = db.create_video(st.session_state.user_id, {\n                'title': topic[:100],\n                'topic': topic,\n                'file_path': video_path,\n                'duration': duration,\n                'quality': quality,\n                'language': st.session_state.language,\n                'status': 'completed'\n            })\n            \n            # Display result\n            st.success(get_text('video.success', st.session_state.language))\n            \n            if os.path.exists(video_path):\n                st.video(video_path)\n                \n                with open(video_path, 'rb') as f:\n                    st.download_button(\n                        label=get_text('video.download', st.session_state.language),\n                        data=f,\n                        file_name=f\"nanotik_{topic[:20]}.mp4\",\n                        mime=\"video/mp4\"\n                    )\n        else:\n            st.error(get_text('credits.insufficient', st.session_state.language))\n        \n    except Exception as e:\n        st.error(f\"{get_text('video.error', st.session_state.language)}: {str(e)}\")\n        status_text.text(\"\")\n        progress_bar.empty()\n\n\ndef render_gallery():\n    \"\"\"Render user's video gallery from database\"\"\"\n    st.header(get_text('gallery.title', st.session_state.language))\n    \n    videos = db.get_user_videos(st.session_state.user_id, limit=30)\n    \n    if not videos:\n        st.info(get_text('gallery.empty', st.session_state.language))\n        return\n    \n    cols = st.columns(3)\n    for idx, video in enumerate(videos):\n        with cols[idx % 3]:\n            if os.path.exists(video['file_path']):\n                st.video(video['file_path'])\n                st.caption(video['title'])\n                st.caption(f\"{get_text('gallery.created', st.session_state.language)}: {video['created_at'].strftime('%Y-%m-%d %H:%M')}\")\n\n\ndef main():\n    \"\"\"Main application entry point\"\"\"\n    render_header()\n    render_sidebar()\n    \n    # Main content tabs\n    tab1, tab2, tab3 = st.tabs([\n        get_text('tabs.create', st.session_state.language),\n        get_text('tabs.gallery', st.session_state.language),\n        get_text('tabs.about', st.session_state.language)\n    ])\n    \n    with tab1:\n        render_video_generator()\n    \n    with tab2:\n        render_gallery()\n    \n    with tab3:\n        st.markdown(get_text('about.content', st.session_state.language))\n        \n        # Feature list\n        st.subheader(get_text('about.features', st.session_state.language))\n        features = [\n            'about.feature1',\n            'about.feature2',\n            'about.feature3',\n            'about.feature4',\n            'about.feature5'\n        ]\n        for feature in features:\n            st.write(f\"- {get_text(feature, st.session_state.language)}\")\n    \n    # Footer\n    st.divider()\n    st.caption(get_text('footer.text', st.session_state.language))\n\n\nif __name__ == \"__main__\":\n    main()\n","size_bytes":13182},"app/models/__init__.py":{"content":"\"\"\"\nNanoTik Models Package\n\"\"\"\n\nfrom .user import UserSession\n\n__all__ = ['UserSession']\n","size_bytes":89},"app/models/user.py":{"content":"\"\"\"\nUser session and data models\n\"\"\"\n\nfrom typing import List, Dict, Any\nfrom datetime import datetime\nimport uuid\n\n\nclass UserSession:\n    \"\"\"User session model for tracking user state\"\"\"\n    \n    def __init__(self):\n        self.session_id = str(uuid.uuid4())\n        self.created_at = datetime.utcnow()\n        self.credits = 0\n        self.videos = []\n        self.transactions = []\n    \n    def add_credits(self, amount: int):\n        \"\"\"Add credits to user account\"\"\"\n        self.credits += amount\n    \n    def deduct_credits(self, amount: int) -> bool:\n        \"\"\"\n        Deduct credits from user account\n        Returns True if successful, False if insufficient credits\n        \"\"\"\n        if self.credits >= amount:\n            self.credits -= amount\n            return True\n        return False\n    \n    def add_video(self, video_data: Dict[str, Any]):\n        \"\"\"Add a generated video to user's gallery\"\"\"\n        video = {\n            'id': str(uuid.uuid4()),\n            'created_at': datetime.utcnow().isoformat(),\n            **video_data\n        }\n        self.videos.append(video)\n    \n    def get_videos(self) -> List[Dict[str, Any]]:\n        \"\"\"Get all videos for this user\"\"\"\n        return self.videos\n    \n    def add_transaction(self, transaction_data: Dict[str, Any]):\n        \"\"\"Record a payment transaction\"\"\"\n        transaction = {\n            'id': str(uuid.uuid4()),\n            'timestamp': datetime.utcnow().isoformat(),\n            **transaction_data\n        }\n        self.transactions.append(transaction)\n    \n    def get_transaction_history(self) -> List[Dict[str, Any]]:\n        \"\"\"Get payment transaction history\"\"\"\n        return self.transactions\n","size_bytes":1689},"app/services/__init__.py":{"content":"\"\"\"\nNanoTik Services Package\n\"\"\"\n\nfrom .llm_service import LLMService\nfrom .payment_service import PaymentService\nfrom .video_service import VideoService\n\n__all__ = ['LLMService', 'PaymentService', 'VideoService']\n","size_bytes":214},"app/services/llm_service.py":{"content":"\"\"\"\nLLM Service for script generation\nSupports multiple AI providers: OpenAI, DeepSeek, Moonshot\n\"\"\"\n\nimport os\nfrom typing import Dict, Any, List\nimport openai\nfrom openai import OpenAI\n\n\nclass LLMService:\n    \"\"\"Service for interacting with Large Language Models\"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.provider = config['app'].get('llm_provider', 'openai')\n        self._initialize_client()\n    \n    def _initialize_client(self):\n        \"\"\"Initialize the appropriate LLM client based on provider\"\"\"\n        if self.provider == 'openai':\n            api_key = self.config['app'].get('openai_api_key')\n            base_url = self.config['app'].get('openai_base_url', 'https://api.openai.com/v1')\n            self.client = OpenAI(api_key=api_key, base_url=base_url)\n            self.model = self.config['app'].get('openai_model_name', 'gpt-4')\n        \n        elif self.provider == 'deepseek':\n            api_key = self.config['app'].get('deepseek_api_key')\n            self.client = OpenAI(\n                api_key=api_key,\n                base_url='https://api.deepseek.com/v1'\n            )\n            self.model = 'deepseek-chat'\n        \n        elif self.provider == 'moonshot':\n            api_key = self.config['app'].get('moonshot_api_key')\n            self.client = OpenAI(\n                api_key=api_key,\n                base_url='https://api.moonshot.cn/v1'\n            )\n            self.model = 'moonshot-v1-8k'\n        \n        else:\n            raise ValueError(f\"Unsupported LLM provider: {self.provider}\")\n    \n    def generate_script(self, topic: str, duration: int, language: str = 'en') -> Dict[str, Any]:\n        \"\"\"\n        Generate a video script based on topic and duration\n        \n        Args:\n            topic: The video topic\n            duration: Target duration in seconds\n            language: Language code (en, zh, ar)\n        \n        Returns:\n            Dictionary with script, scenes, and metadata\n        \"\"\"\n        prompt = self._build_script_prompt(topic, duration, language)\n        \n        try:\n            response = self.client.chat.completions.create(\n                model=self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": self._get_system_prompt(language)},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                temperature=0.7,\n                max_tokens=2000\n            )\n            \n            content = response.choices[0].message.content\n            if content is None:\n                raise Exception(\"No content received from LLM\")\n            return self._parse_script_response(content)\n        \n        except Exception as e:\n            raise Exception(f\"Failed to generate script: {str(e)}\")\n    \n    def _get_system_prompt(self, language: str) -> str:\n        \"\"\"Get system prompt based on language\"\"\"\n        prompts = {\n            'en': \"You are a professional video script writer. Create engaging, informative scripts for short-form videos.\",\n            'zh': \"ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è§†é¢‘è„šæœ¬ä½œå®¶ã€‚ä¸ºçŸ­è§†é¢‘åˆ›ä½œå¼•äººå…¥èƒœã€ä¿¡æ¯ä¸°å¯Œçš„è„šæœ¬ã€‚\",\n            'ar': \"Ø£Ù†Øª ÙƒØ§ØªØ¨ Ù…Ø­ØªØ±Ù Ù„Ù†ØµÙˆØµ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ. Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù†ØµÙˆØµ Ø¬Ø°Ø§Ø¨Ø© ÙˆÙ…ÙÙŠØ¯Ø© Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù‚ØµÙŠØ±Ø©.\"\n        }\n        return prompts.get(language, prompts['en'])\n    \n    def _build_script_prompt(self, topic: str, duration: int, language: str) -> str:\n        \"\"\"Build the prompt for script generation\"\"\"\n        word_count = duration * 2  # Approximate 2 words per second\n        \n        prompts = {\n            'en': f\"\"\"Create a {duration}-second video script about: {topic}\n\nRequirements:\n- Approximately {word_count} words\n- Include 5-7 distinct scenes\n- Each scene should have a description and narration\n- Make it engaging and informative\n- Include visual suggestions for each scene\n\nFormat your response as:\nScene 1: [Visual description]\nNarration: [What to say]\n\nScene 2: [Visual description]\nNarration: [What to say]\n...\"\"\",\n            'zh': f\"\"\"åˆ›å»ºä¸€ä¸ª{duration}ç§’çš„è§†é¢‘è„šæœ¬ï¼Œä¸»é¢˜ï¼š{topic}\n\nè¦æ±‚ï¼š\n- å¤§çº¦{word_count}å­—\n- åŒ…å«5-7ä¸ªä¸åŒçš„åœºæ™¯\n- æ¯ä¸ªåœºæ™¯åº”æœ‰æè¿°å’Œæ—ç™½\n- å†…å®¹å¼•äººå…¥èƒœä¸”ä¿¡æ¯ä¸°å¯Œ\n- ä¸ºæ¯ä¸ªåœºæ™¯æä¾›è§†è§‰å»ºè®®\n\næŒ‰ä»¥ä¸‹æ ¼å¼å›žå¤ï¼š\nåœºæ™¯1ï¼š[è§†è§‰æè¿°]\næ—ç™½ï¼š[è¦è¯´çš„å†…å®¹]\n\nåœºæ™¯2ï¼š[è§†è§‰æè¿°]\næ—ç™½ï¼š[è¦è¯´çš„å†…å®¹]\n...\"\"\",\n            'ar': f\"\"\"Ø£Ù†Ø´Ø¦ Ù†Øµ ÙÙŠØ¯ÙŠÙˆ Ù…Ø¯ØªÙ‡ {duration} Ø«Ø§Ù†ÙŠØ© Ø­ÙˆÙ„: {topic}\n\nØ§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª:\n- Ø­ÙˆØ§Ù„ÙŠ {word_count} ÙƒÙ„Ù…Ø©\n- ÙŠØ´Ù…Ù„ 5-7 Ù…Ø´Ø§Ù‡Ø¯ Ù…ØªÙ…ÙŠØ²Ø©\n- ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù„ÙƒÙ„ Ù…Ø´Ù‡Ø¯ ÙˆØµÙ ÙˆØ³Ø±Ø¯\n- Ø§Ø¬Ø¹Ù„Ù‡ Ø¬Ø°Ø§Ø¨Ù‹Ø§ ÙˆØºÙ†ÙŠÙ‹Ø§ Ø¨Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª\n- Ù‚Ø¯Ù… Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø¨ØµØ±ÙŠØ© Ù„ÙƒÙ„ Ù…Ø´Ù‡Ø¯\n\nØµÙŠØºØ© Ø§Ù„Ø±Ø¯:\nØ§Ù„Ù…Ø´Ù‡Ø¯ 1: [Ø§Ù„ÙˆØµÙ Ø§Ù„Ø¨ØµØ±ÙŠ]\nØ§Ù„Ø³Ø±Ø¯: [Ù…Ø§ ÙŠØ¬Ø¨ Ù‚ÙˆÙ„Ù‡]\n\nØ§Ù„Ù…Ø´Ù‡Ø¯ 2: [Ø§Ù„ÙˆØµÙ Ø§Ù„Ø¨ØµØ±ÙŠ]\nØ§Ù„Ø³Ø±Ø¯: [Ù…Ø§ ÙŠØ¬Ø¨ Ù‚ÙˆÙ„Ù‡]\n...\"\"\"\n        }\n        \n        return prompts.get(language, prompts['en'])\n    \n    def _parse_script_response(self, content: str) -> Dict[str, Any]:\n        \"\"\"Parse the LLM response into structured script data\"\"\"\n        scenes = []\n        current_scene = None\n        \n        lines = content.split('\\n')\n        for line in lines:\n            line = line.strip()\n            if not line:\n                continue\n            \n            # Check for scene markers in multiple languages\n            if any(marker in line.lower() for marker in ['scene', 'åœºæ™¯', 'Ø§Ù„Ù…Ø´Ù‡Ø¯']):\n                if current_scene:\n                    scenes.append(current_scene)\n                current_scene = {'description': '', 'narration': ''}\n                # Extract scene description\n                if ':' in line:\n                    current_scene['description'] = line.split(':', 1)[1].strip()\n            \n            elif any(marker in line.lower() for marker in ['narration', 'æ—ç™½', 'Ø§Ù„Ø³Ø±Ø¯']):\n                if current_scene and ':' in line:\n                    current_scene['narration'] = line.split(':', 1)[1].strip()\n        \n        # Add the last scene\n        if current_scene:\n            scenes.append(current_scene)\n        \n        # Compile full narration\n        full_narration = ' '.join([scene['narration'] for scene in scenes if scene.get('narration')])\n        \n        return {\n            'scenes': scenes,\n            'narration': full_narration,\n            'scene_count': len(scenes)\n        }\n","size_bytes":6537},"app/services/payment_service.py":{"content":"\"\"\"\nPayment Service for Nano cryptocurrency transactions\nIntegrates with NANO MCP Server for payment processing\n\"\"\"\n\nimport os\nimport requests\nfrom typing import Dict, Any\nimport uuid\nfrom datetime import datetime\n\n\nclass PaymentService:\n    \"\"\"Service for handling Nano cryptocurrency payments\"\"\"\n    \n    def __init__(self):\n        self.nano_mcp_url = os.getenv('NANO_MCP_URL', 'https://nano-mcp.replit.app')\n        self.wallet_address = os.getenv('NANO_WALLET_ADDRESS', '')\n    \n    def create_payment_request(self, amount: float, credits: int, user_id: str = None) -> Dict[str, Any]:\n        \"\"\"\n        Create a payment request for credit purchase\n        \n        Args:\n            amount: Amount in NANO\n            credits: Number of credits to purchase\n            user_id: User ID for transaction tracking (optional)\n        \n        Returns:\n            Payment request details including QR code and payment address\n        \"\"\"\n        payment_id = str(uuid.uuid4())\n        \n        try:\n            # In a real implementation, this would call the NANO MCP Server\n            # For now, we'll simulate the payment flow\n            \n            # Generate payment address (in real implementation, from MCP server)\n            payment_address = self._generate_payment_address()\n            \n            payment_request = {\n                'success': True,\n                'payment_id': payment_id,\n                'amount': amount,\n                'credits': credits,\n                'currency': 'NANO',\n                'payment_address': payment_address,\n                'created_at': datetime.utcnow().isoformat(),\n                'status': 'pending',\n                'expires_at': self._get_expiry_time(),\n                'user_id': user_id\n            }\n            \n            # Save to database if user_id provided\n            if user_id:\n                from app.database import get_database\n                db = get_database()\n                transaction = db.create_transaction(user_id, {\n                    'transaction_type': 'purchase',\n                    'amount': float(amount),  # Store as float for now\n                    'credits': credits,\n                    'currency': 'NANO',\n                    'payment_id': payment_id,\n                    'status': 'pending'  # Start as pending\n                })\n                \n                # For DEMO ONLY: Immediately mark as completed\n                # In production, this would wait for Nano MCP webhook confirmation\n                db.update_transaction_status(transaction['id'], 'completed')\n                payment_request['status'] = 'completed'\n                payment_request['transaction_id'] = transaction['id']\n            \n            return payment_request\n        \n        except Exception as e:\n            return {\n                'success': False,\n                'error': str(e)\n            }\n    \n    def verify_payment(self, payment_id: str) -> Dict[str, Any]:\n        \"\"\"\n        Verify if a payment has been completed\n        \n        Args:\n            payment_id: The payment request ID\n        \n        Returns:\n            Payment verification status\n        \"\"\"\n        try:\n            # In real implementation, check with NANO MCP Server\n            # For demo, we'll simulate successful payment after a delay\n            \n            return {\n                'success': True,\n                'payment_id': payment_id,\n                'status': 'completed',\n                'verified_at': datetime.utcnow().isoformat()\n            }\n        \n        except Exception as e:\n            return {\n                'success': False,\n                'error': str(e)\n            }\n    \n    def get_payment_status(self, payment_id: str) -> str:\n        \"\"\"\n        Get current status of a payment\n        \n        Returns: 'pending', 'completed', 'failed', 'expired'\n        \"\"\"\n        # In real implementation, query NANO MCP Server\n        return 'completed'\n    \n    def _generate_payment_address(self) -> str:\n        \"\"\"Generate or retrieve a payment address\"\"\"\n        if self.wallet_address:\n            return self.wallet_address\n        \n        # In real implementation, request from NANO MCP Server\n        return 'nano_3demo_address_for_testing_purposes_only_1234567890'\n    \n    def _get_expiry_time(self) -> str:\n        \"\"\"Get payment expiry time (15 minutes from now)\"\"\"\n        from datetime import timedelta\n        expiry = datetime.utcnow() + timedelta(minutes=15)\n        return expiry.isoformat()\n    \n    def get_transaction_history(self, user_id: str) -> list:\n        \"\"\"\n        Get payment transaction history for a user\n        \n        Args:\n            user_id: User identifier\n        \n        Returns:\n            List of transaction records\n        \"\"\"\n        # In real implementation, fetch from database\n        return []\n","size_bytes":4862},"app/services/video_service.py":{"content":"\"\"\"\nVideo Service for video generation and composition\nHandles script generation, voiceover, video clips, and final composition\n\"\"\"\n\nimport os\nfrom typing import Dict, Any, List\nfrom pathlib import Path\nimport tempfile\nimport requests\nimport azure.cognitiveservices.speech as speechsdk\nfrom pexels_api import API as PexelsAPI\nfrom moviepy import VideoFileClip, AudioFileClip, concatenate_videoclips\nfrom moviepy.video import fx as vfx\nfrom contextlib import ExitStack\nfrom .llm_service import LLMService\n\n\nclass VideoService:\n    \"\"\"Service for video generation operations\"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.llm_service = LLMService(config)\n        self.output_dir = Path(config['video'].get('output_dir', './output'))\n        self.temp_dir = Path(config['video'].get('temp_dir', './temp'))\n        \n        # Create directories\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        self.temp_dir.mkdir(parents=True, exist_ok=True)\n        \n        # Initialize Pexels API\n        pexels_keys = self.config['app'].get('pexels_api_keys', [])\n        self.pexels_api = PexelsAPI(pexels_keys[0]) if pexels_keys else None\n        \n        # Initialize Azure Speech\n        speech_key = self.config['azure'].get('speech_key', '')\n        speech_region = self.config['azure'].get('speech_region', 'eastus')\n        if speech_key:\n            self.speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n        else:\n            self.speech_config = None\n    \n    def generate_script(self, topic: str, duration: int, language: str = 'en') -> Dict[str, Any]:\n        \"\"\"\n        Generate video script using LLM\n        \n        Args:\n            topic: Video topic\n            duration: Target duration in seconds\n            language: Language code\n        \n        Returns:\n            Script data with scenes and narration\n        \"\"\"\n        return self.llm_service.generate_script(topic, duration, language)\n    \n    def generate_voiceover(self, script: Dict[str, Any], voice: str, language: str = 'en') -> str:\n        \"\"\"\n        Generate voiceover audio from script using Azure TTS\n        \n        Args:\n            script: Script data with narration\n            voice: Voice type (male, female, neutral)\n            language: Language code\n        \n        Returns:\n            Path to generated audio file\n        \"\"\"\n        audio_file = self.temp_dir / f\"voiceover_{os.urandom(8).hex()}.wav\"\n        \n        if not self.speech_config:\n            raise Exception(\"Azure Speech Services not configured. Please add AZURE_SPEECH_KEY and AZURE_SPEECH_REGION.\")\n        \n        try:\n            # Select voice based on language and gender\n            voice_map = {\n                'en': {'male': 'en-US-GuyNeural', 'female': 'en-US-JennyNeural', 'neutral': 'en-US-AriaNeural'},\n                'zh': {'male': 'zh-CN-YunxiNeural', 'female': 'zh-CN-XiaoxiaoNeural', 'neutral': 'zh-CN-YunyangNeural'},\n                'ar': {'male': 'ar-SA-HamedNeural', 'female': 'ar-SA-ZariyahNeural', 'neutral': 'ar-SA-HamedNeural'}\n            }\n            \n            selected_voice = voice_map.get(language, voice_map['en']).get(voice, voice_map['en']['neutral'])\n            self.speech_config.speech_synthesis_voice_name = selected_voice\n            \n            # Configure audio output\n            audio_config = speechsdk.audio.AudioOutputConfig(filename=str(audio_file))\n            synthesizer = speechsdk.SpeechSynthesizer(speech_config=self.speech_config, audio_config=audio_config)\n            \n            # Generate speech\n            narration_text = script.get('narration', '')\n            if not narration_text:\n                raise Exception(\"No narration text found in script\")\n            \n            result = synthesizer.speak_text_async(narration_text).get()\n            \n            if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n                return str(audio_file)\n            elif result.reason == speechsdk.ResultReason.Canceled:\n                cancellation = result.cancellation_details\n                # Clean up partial file\n                if audio_file.exists():\n                    audio_file.unlink()\n                raise Exception(f\"Speech synthesis canceled: {cancellation.reason}. Error: {cancellation.error_details}\")\n            else:\n                # Clean up partial file\n                if audio_file.exists():\n                    audio_file.unlink()\n                raise Exception(f\"Speech synthesis failed with reason: {result.reason}\")\n        except Exception as e:\n            # Clean up on any error\n            if audio_file.exists():\n                audio_file.unlink()\n            raise\n    \n    def search_video_clips(self, script: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search for video clips based on script scenes using Pexels API\n        \n        Args:\n            script: Script data with scenes\n        \n        Returns:\n            List of video clip metadata with download URLs\n        \"\"\"\n        clips = []\n        \n        if not self.pexels_api:\n            raise Exception(\"Pexels API not configured. Please add PEXELS_API_KEYS.\")\n        \n        for idx, scene in enumerate(script.get('scenes', [])):\n            query = scene.get('description', '')[:100]  # Limit query length\n            if not query:\n                continue\n            \n            try:\n                # Search for videos on Pexels using correct API\n                self.pexels_api.search_videos(query, page=1, results_per_page=3)\n                videos = self.pexels_api.get_entries()\n                \n                if videos and len(videos) > 0:\n                    # Try each video until we find one with valid files\n                    for video in videos:\n                        video_files = video.video_files if hasattr(video, 'video_files') else []\n                        \n                        if not video_files:\n                            continue\n                        \n                        # Find the best quality video file (prefer HD, highest bitrate)\n                        best_file = None\n                        best_score = 0\n                        \n                        for vf in video_files:\n                            width = getattr(vf, 'width', 0)\n                            quality = getattr(vf, 'quality', '')\n                            \n                            # Score: HD quality + higher resolution\n                            score = (1000 if quality == 'hd' else 0) + width\n                            \n                            if score > best_score and width >= 1280:\n                                best_file = vf\n                                best_score = score\n                        \n                        # Fallback to first available file if no HD found\n                        if not best_file and video_files:\n                            best_file = video_files[0]\n                        \n                        if best_file:\n                            clip = {\n                                'id': getattr(video, 'id', f\"clip_{idx}\"),\n                                'url': getattr(best_file, 'link', ''),\n                                'description': query,\n                                'duration': getattr(video, 'duration', 5),\n                                'width': getattr(best_file, 'width', 1920),\n                                'height': getattr(best_file, 'height', 1080),\n                                'source': 'pexels'\n                            }\n                            \n                            if clip['url']:\n                                clips.append(clip)\n                                break  # Found a good clip for this scene\n                        \n            except Exception as e:\n                print(f\"Warning: Failed to fetch clip for scene {idx}: {str(e)}\")\n                continue\n        \n        if not clips:\n            raise Exception(\"Could not find any suitable video clips for the script scenes\")\n        \n        return clips\n    \n    def compose_video(\n        self,\n        clips: List[Dict[str, Any]],\n        audio_path: str,\n        script: Dict[str, Any],\n        subtitle_position: str = 'bottom',\n        quality: str = 'basic',\n        music: bool = True\n    ) -> str:\n        \"\"\"\n        Compose final video from clips and audio using MoviePy\n        \n        Args:\n            clips: List of video clip data with URLs\n            audio_path: Path to voiceover audio file\n            script: Script data (unused for now)\n            subtitle_position: Subtitle position (unused for now)\n            quality: Video quality setting (basic, hd, premium)\n            music: Background music flag (unused for now)\n        \n        Returns:\n            Path to final video file\n        \"\"\"\n        output_file = self.output_dir / f\"video_{os.urandom(8).hex()}.mp4\"\n        downloaded_clips = []\n        \n        with ExitStack() as stack:\n            try:\n                # Step 1: Download video clips\n                for i, clip in enumerate(clips):\n                    clip_path = self.temp_dir / f\"clip_{i}_{os.urandom(4).hex()}.mp4\"\n                    try:\n                        response = requests.get(clip['url'], stream=True, timeout=30)\n                        response.raise_for_status()\n                        \n                        with open(clip_path, 'wb') as f:\n                            for chunk in response.iter_content(chunk_size=8192):\n                                f.write(chunk)\n                        \n                        downloaded_clips.append(clip_path)\n                    except Exception as e:\n                        print(f\"Warning: Failed to download clip {i}: {str(e)}\")\n                        continue\n                \n                if not downloaded_clips:\n                    raise Exception(\"Failed to download any video clips\")\n                \n                # Step 2: Load audio to get duration\n                audio_clip = stack.enter_context(AudioFileClip(audio_path))\n                total_audio_duration = audio_clip.duration\n                \n                # Step 3: Load and process video clips\n                target_resolution = (1920, 1080) if quality in ['hd', 'premium'] else (1280, 720)\n                video_clips = []\n                \n                for clip_path in downloaded_clips:\n                    try:\n                        video = stack.enter_context(VideoFileClip(str(clip_path)))\n                        # Resize to target resolution\n                        video = video.resize(target_resolution)\n                        video_clips.append(video)\n                    except Exception as e:\n                        print(f\"Warning: Failed to load clip {clip_path}: {str(e)}\")\n                        continue\n                \n                if not video_clips:\n                    raise Exception(\"Failed to load any video clips\")\n                \n                # Step 4: Adjust clip durations to match audio\n                duration_per_clip = total_audio_duration / len(video_clips)\n                adjusted_clips = []\n                \n                for video in video_clips:\n                    if video.duration > duration_per_clip:\n                        # Trim if too long\n                        adjusted = video.subclip(0, duration_per_clip)\n                    else:\n                        # Loop if too short - manually concatenate copies\n                        loops_needed = int(duration_per_clip / video.duration) + 1\n                        looped = concatenate_videoclips([video] * loops_needed)\n                        adjusted = looped.subclip(0, duration_per_clip)\n                    \n                    adjusted_clips.append(adjusted)\n                \n                # Step 5: Concatenate all clips\n                final_video = concatenate_videoclips(adjusted_clips, method=\"compose\")\n                \n                # Step 6: Add audio\n                final_video = final_video.with_audio(audio_clip)\n                \n                # Step 7: Set quality parameters\n                quality_settings = {\n                    'basic': {'bitrate': '1000k', 'audio_bitrate': '128k'},\n                    'hd': {'bitrate': '2500k', 'audio_bitrate': '192k'},\n                    'premium': {'bitrate': '5000k', 'audio_bitrate': '256k'}\n                }\n                \n                settings = quality_settings.get(quality, quality_settings['basic'])\n                \n                # Step 8: Write output file\n                final_video.write_videofile(\n                    str(output_file),\n                    codec='libx264',\n                    audio_codec='aac',\n                    bitrate=settings['bitrate'],\n                    audio_bitrate=settings['audio_bitrate'],\n                    fps=24,\n                    preset='medium',\n                    threads=2,\n                    logger=None  # Suppress verbose output\n                )\n                \n                # Clean up adjusted clips and final video\n                for clip in adjusted_clips:\n                    try:\n                        clip.close()\n                    except:\n                        pass\n                \n                try:\n                    final_video.close()\n                except:\n                    pass\n                \n                return str(output_file)\n                \n            finally:\n                # Always clean up downloaded temp files\n                for clip_path in downloaded_clips:\n                    try:\n                        clip_path.unlink()\n                    except:\n                        pass\n","size_bytes":13799},"app/utils/__init__.py":{"content":"\"\"\"\nNanoTik Utilities Package\n\"\"\"\n\nfrom .i18n import get_text, set_language, SUPPORTED_LANGUAGES\n\n__all__ = ['get_text', 'set_language', 'SUPPORTED_LANGUAGES']\n","size_bytes":160},"app/utils/i18n.py":{"content":"\"\"\"\nInternationalization utilities for multi-language support\nSupports English, Chinese (Simplified), and Arabic\n\"\"\"\n\nfrom typing import Dict, Any\n\nSUPPORTED_LANGUAGES = {\n    'en': 'ðŸ‡¬ðŸ‡§ English',\n    'zh': 'ðŸ‡¨ðŸ‡³ ç®€ä½“ä¸­æ–‡',\n    'ar': 'ðŸ‡¸ðŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©'\n}\n\nTRANSLATIONS = {\n    'en': {\n        'app.subtitle': 'AI-Powered Video Generator with Nano Payments',\n        'language.select': 'Language',\n        'credits.balance': 'Credits',\n        'credits.name': 'credits',\n        'credits.bonus': 'bonus',\n        'credits.buy': 'ðŸ’° Buy Credits',\n        'credits.purchase': 'Purchase',\n        'credits.info': 'ðŸ’¡ Credits are used to generate videos. Different quality levels require different amounts of credits.',\n        'credits.costs': 'Credit Costs',\n        'credits.insufficient': 'âš ï¸ Insufficient credits. Please purchase more credits to continue.',\n        'credits.buy_prompt': 'ðŸ‘‰ Use the sidebar to purchase credits with Nano cryptocurrency.',\n        'payment.processing': 'Processing payment...',\n        'payment.success': 'âœ… Payment successful! Credits added to your account.',\n        'payment.failed': 'âŒ Payment failed. Please try again.',\n        'payment.error': 'Payment error',\n        'video.generate': 'ðŸŽ¬ Generate Video',\n        'video.topic': 'Video Topic',\n        'video.topic_placeholder': 'Enter the topic for your video...',\n        'video.topic_required': 'Please enter a video topic.',\n        'video.quality': 'Video Quality',\n        'video.duration': 'Duration (seconds)',\n        'video.advanced': 'âš™ï¸ Advanced Options',\n        'video.voice': 'Voice Type',\n        'video.music': 'Add Background Music',\n        'video.subtitle_position': 'Subtitle Position',\n        'video.create': 'ðŸš€ Create Video',\n        'video.basic': 'Basic (1 credit)',\n        'video.hd': 'HD (2 credits)',\n        'video.premium': 'Premium (3 credits)',\n        'video.generating_script': 'Generating script with AI...',\n        'video.generating_voice': 'Creating voiceover...',\n        'video.searching_clips': 'Searching for video clips...',\n        'video.composing': 'Composing final video...',\n        'video.complete': 'Video generation complete!',\n        'video.success': 'ðŸŽ‰ Your video is ready!',\n        'video.download': 'ðŸ“¥ Download Video',\n        'video.error': 'Video generation error',\n        'gallery.title': 'ðŸŽžï¸ My Videos',\n        'gallery.empty': 'No videos yet. Create your first video!',\n        'gallery.created': 'Created',\n        'tabs.create': 'ðŸŽ¬ Create',\n        'tabs.gallery': 'ðŸŽžï¸ Gallery',\n        'tabs.about': 'â„¹ï¸ About',\n        'about.content': '''\n## About NanoTik\n\nNanoTik is an AI-powered video generator that uses cutting-edge technology to create professional videos from simple text prompts.\n\n### How It Works\n1. **Choose a Topic**: Tell us what your video should be about\n2. **AI Script Generation**: Our AI creates an engaging script\n3. **Automated Production**: We generate voiceovers, find clips, and compose your video\n4. **Download & Share**: Get your professional video in minutes\n        ''',\n        'about.features': 'âœ¨ Features',\n        'about.feature1': 'ðŸ¤– AI-powered script generation',\n        'about.feature2': 'ðŸ’° Instant Nano cryptocurrency payments',\n        'about.feature3': 'ðŸŒ Multi-language support (English, Chinese, Arabic)',\n        'about.feature4': 'ðŸ“± Responsive design for all devices',\n        'about.feature5': 'ðŸŽ¨ Professional quality output',\n        'footer.text': 'Â© 2025 NanoTik - Built with â¤ï¸ using Streamlit'\n    },\n    'zh': {\n        'app.subtitle': 'åŸºäºŽAIçš„è§†é¢‘ç”Ÿæˆå™¨ï¼Œæ”¯æŒNanoæ”¯ä»˜',\n        'language.select': 'è¯­è¨€',\n        'credits.balance': 'ç§¯åˆ†',\n        'credits.name': 'ç§¯åˆ†',\n        'credits.bonus': 'å¥–åŠ±',\n        'credits.buy': 'ðŸ’° è´­ä¹°ç§¯åˆ†',\n        'credits.purchase': 'è´­ä¹°',\n        'credits.info': 'ðŸ’¡ ç§¯åˆ†ç”¨äºŽç”Ÿæˆè§†é¢‘ã€‚ä¸åŒçš„è´¨é‡çº§åˆ«éœ€è¦ä¸åŒæ•°é‡çš„ç§¯åˆ†ã€‚',\n        'credits.costs': 'ç§¯åˆ†æ¶ˆè´¹',\n        'credits.insufficient': 'âš ï¸ ç§¯åˆ†ä¸è¶³ã€‚è¯·è´­ä¹°æ›´å¤šç§¯åˆ†ä»¥ç»§ç»­ã€‚',\n        'credits.buy_prompt': 'ðŸ‘‰ ä½¿ç”¨ä¾§è¾¹æ é€šè¿‡NanoåŠ å¯†è´§å¸è´­ä¹°ç§¯åˆ†ã€‚',\n        'payment.processing': 'æ­£åœ¨å¤„ç†ä»˜æ¬¾...',\n        'payment.success': 'âœ… ä»˜æ¬¾æˆåŠŸï¼ç§¯åˆ†å·²æ·»åŠ åˆ°æ‚¨çš„è´¦æˆ·ã€‚',\n        'payment.failed': 'âŒ ä»˜æ¬¾å¤±è´¥ã€‚è¯·é‡è¯•ã€‚',\n        'payment.error': 'ä»˜æ¬¾é”™è¯¯',\n        'video.generate': 'ðŸŽ¬ ç”Ÿæˆè§†é¢‘',\n        'video.topic': 'è§†é¢‘ä¸»é¢˜',\n        'video.topic_placeholder': 'è¾“å…¥æ‚¨çš„è§†é¢‘ä¸»é¢˜...',\n        'video.topic_required': 'è¯·è¾“å…¥è§†é¢‘ä¸»é¢˜ã€‚',\n        'video.quality': 'è§†é¢‘è´¨é‡',\n        'video.duration': 'æ—¶é•¿ï¼ˆç§’ï¼‰',\n        'video.advanced': 'âš™ï¸ é«˜çº§é€‰é¡¹',\n        'video.voice': 'è¯­éŸ³ç±»åž‹',\n        'video.music': 'æ·»åŠ èƒŒæ™¯éŸ³ä¹',\n        'video.subtitle_position': 'å­—å¹•ä½ç½®',\n        'video.create': 'ðŸš€ åˆ›å»ºè§†é¢‘',\n        'video.basic': 'åŸºç¡€ï¼ˆ1ç§¯åˆ†ï¼‰',\n        'video.hd': 'é«˜æ¸…ï¼ˆ2ç§¯åˆ†ï¼‰',\n        'video.premium': 'ä¸“ä¸šç‰ˆï¼ˆ3ç§¯åˆ†ï¼‰',\n        'video.generating_script': 'æ­£åœ¨ä½¿ç”¨AIç”Ÿæˆè„šæœ¬...',\n        'video.generating_voice': 'æ­£åœ¨åˆ›å»ºé…éŸ³...',\n        'video.searching_clips': 'æ­£åœ¨æœç´¢è§†é¢‘ç‰‡æ®µ...',\n        'video.composing': 'æ­£åœ¨åˆæˆæœ€ç»ˆè§†é¢‘...',\n        'video.complete': 'è§†é¢‘ç”Ÿæˆå®Œæˆï¼',\n        'video.success': 'ðŸŽ‰ æ‚¨çš„è§†é¢‘å·²å‡†å¤‡å°±ç»ªï¼',\n        'video.download': 'ðŸ“¥ ä¸‹è½½è§†é¢‘',\n        'video.error': 'è§†é¢‘ç”Ÿæˆé”™è¯¯',\n        'gallery.title': 'ðŸŽžï¸ æˆ‘çš„è§†é¢‘',\n        'gallery.empty': 'è¿˜æ²¡æœ‰è§†é¢‘ã€‚åˆ›å»ºæ‚¨çš„ç¬¬ä¸€ä¸ªè§†é¢‘ï¼',\n        'gallery.created': 'åˆ›å»ºäºŽ',\n        'tabs.create': 'ðŸŽ¬ åˆ›å»º',\n        'tabs.gallery': 'ðŸŽžï¸ ç”»å»Š',\n        'tabs.about': 'â„¹ï¸ å…³äºŽ',\n        'about.content': '''\n## å…³äºŽNanoTik\n\nNanoTikæ˜¯ä¸€æ¬¾ç”±AIé©±åŠ¨çš„è§†é¢‘ç”Ÿæˆå™¨ï¼Œä½¿ç”¨å°–ç«¯æŠ€æœ¯ä»Žç®€å•çš„æ–‡æœ¬æç¤ºåˆ›å»ºä¸“ä¸šè§†é¢‘ã€‚\n\n### å·¥ä½œåŽŸç†\n1. **é€‰æ‹©ä¸»é¢˜**ï¼šå‘Šè¯‰æˆ‘ä»¬æ‚¨çš„è§†é¢‘ä¸»é¢˜\n2. **AIè„šæœ¬ç”Ÿæˆ**ï¼šæˆ‘ä»¬çš„AIåˆ›å»ºå¼•äººå…¥èƒœçš„è„šæœ¬\n3. **è‡ªåŠ¨åˆ¶ä½œ**ï¼šæˆ‘ä»¬ç”Ÿæˆé…éŸ³ã€æŸ¥æ‰¾ç‰‡æ®µå¹¶åˆæˆæ‚¨çš„è§†é¢‘\n4. **ä¸‹è½½å’Œåˆ†äº«**ï¼šå‡ åˆ†é’Ÿå†…èŽ·å¾—ä¸“ä¸šè§†é¢‘\n        ''',\n        'about.features': 'âœ¨ ç‰¹ç‚¹',\n        'about.feature1': 'ðŸ¤– AIé©±åŠ¨çš„è„šæœ¬ç”Ÿæˆ',\n        'about.feature2': 'ðŸ’° å³æ—¶NanoåŠ å¯†è´§å¸æ”¯ä»˜',\n        'about.feature3': 'ðŸŒ å¤šè¯­è¨€æ”¯æŒï¼ˆè‹±è¯­ã€ä¸­æ–‡ã€é˜¿æ‹‰ä¼¯è¯­ï¼‰',\n        'about.feature4': 'ðŸ“± é€‚ç”¨äºŽæ‰€æœ‰è®¾å¤‡çš„å“åº”å¼è®¾è®¡',\n        'about.feature5': 'ðŸŽ¨ ä¸“ä¸šè´¨é‡è¾“å‡º',\n        'footer.text': 'Â© 2025 NanoTik - ä½¿ç”¨Streamlitæž„å»ºï¼Œå……æ»¡â¤ï¸'\n    },\n    'ar': {\n        'app.subtitle': 'Ù…ÙˆÙ„Ø¯ ÙÙŠØ¯ÙŠÙˆ Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ø¹ Ù…Ø¯ÙÙˆØ¹Ø§Øª Ù†Ø§Ù†Ùˆ',\n        'language.select': 'Ø§Ù„Ù„ØºØ©',\n        'credits.balance': 'Ø§Ù„Ø£Ø±ØµØ¯Ø©',\n        'credits.name': 'Ø£Ø±ØµØ¯Ø©',\n        'credits.bonus': 'Ù…ÙƒØ§ÙØ£Ø©',\n        'credits.buy': 'ðŸ’° Ø´Ø±Ø§Ø¡ Ø§Ù„Ø£Ø±ØµØ¯Ø©',\n        'credits.purchase': 'Ø´Ø±Ø§Ø¡',\n        'credits.info': 'ðŸ’¡ ØªÙØ³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø±ØµØ¯Ø© Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ. ØªØªØ·Ù„Ø¨ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ø®ØªÙ„ÙØ© ÙƒÙ…ÙŠØ§Øª Ù…Ø®ØªÙ„ÙØ© Ù…Ù† Ø§Ù„Ø£Ø±ØµØ¯Ø©.',\n        'credits.costs': 'ØªÙƒØ§Ù„ÙŠÙ Ø§Ù„Ø£Ø±ØµØ¯Ø©',\n        'credits.insufficient': 'âš ï¸ Ø£Ø±ØµØ¯Ø© ØºÙŠØ± ÙƒØ§ÙÙŠØ©. ÙŠØ±Ø¬Ù‰ Ø´Ø±Ø§Ø¡ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø£Ø±ØµØ¯Ø© Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©.',\n        'credits.buy_prompt': 'ðŸ‘‰ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ù„Ø´Ø±Ø§Ø¡ Ø§Ù„Ø£Ø±ØµØ¯Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ù…Ù„Ø© Ù†Ø§Ù†Ùˆ Ø§Ù„Ù…Ø´ÙØ±Ø©.',\n        'payment.processing': 'Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯ÙØ¹...',\n        'payment.success': 'âœ… ØªÙ… Ø§Ù„Ø¯ÙØ¹ Ø¨Ù†Ø¬Ø§Ø­! ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø±ØµØ¯Ø© Ø¥Ù„Ù‰ Ø­Ø³Ø§Ø¨Ùƒ.',\n        'payment.failed': 'âŒ ÙØ´Ù„ Ø§Ù„Ø¯ÙØ¹. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.',\n        'payment.error': 'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¯ÙØ¹',\n        'video.generate': 'ðŸŽ¬ Ø¥Ù†Ø´Ø§Ø¡ ÙÙŠØ¯ÙŠÙˆ',\n        'video.topic': 'Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ',\n        'video.topic_placeholder': 'Ø£Ø¯Ø®Ù„ Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ...',\n        'video.topic_required': 'ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ.',\n        'video.quality': 'Ø¬ÙˆØ¯Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ',\n        'video.duration': 'Ø§Ù„Ù…Ø¯Ø© (Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ)',\n        'video.advanced': 'âš™ï¸ Ø®ÙŠØ§Ø±Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©',\n        'video.voice': 'Ù†ÙˆØ¹ Ø§Ù„ØµÙˆØª',\n        'video.music': 'Ø¥Ø¶Ø§ÙØ© Ù…ÙˆØ³ÙŠÙ‚Ù‰ Ø®Ù„ÙÙŠØ©',\n        'video.subtitle_position': 'Ù…ÙˆØ¶Ø¹ Ø§Ù„ØªØ±Ø¬Ù…Ø©',\n        'video.create': 'ðŸš€ Ø¥Ù†Ø´Ø§Ø¡ ÙÙŠØ¯ÙŠÙˆ',\n        'video.basic': 'Ø£Ø³Ø§Ø³ÙŠ (Ø±ØµÙŠØ¯ ÙˆØ§Ø­Ø¯)',\n        'video.hd': 'Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø¯Ù‚Ø© (Ø±ØµÙŠØ¯Ø§Ù†)',\n        'video.premium': 'Ù…ØªÙ…ÙŠØ² (3 Ø£Ø±ØµØ¯Ø©)',\n        'video.generating_script': 'Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ...',\n        'video.generating_voice': 'Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ Ø§Ù„ØµÙˆØªÙŠ...',\n        'video.searching_clips': 'Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ...',\n        'video.composing': 'Ø¬Ø§Ø±ÙŠ ØªØ±ÙƒÙŠØ¨ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ...',\n        'video.complete': 'Ø§ÙƒØªÙ…Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ!',\n        'video.success': 'ðŸŽ‰ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ø¬Ø§Ù‡Ø²!',\n        'video.download': 'ðŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ',\n        'video.error': 'Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ',\n        'gallery.title': 'ðŸŽžï¸ Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø®Ø§ØµØ© Ø¨ÙŠ',\n        'gallery.empty': 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù‚Ø§Ø·Ø¹ ÙÙŠØ¯ÙŠÙˆ Ø¨Ø¹Ø¯. Ø£Ù†Ø´Ø¦ Ø£ÙˆÙ„ ÙÙŠØ¯ÙŠÙˆ Ù„Ùƒ!',\n        'gallery.created': 'ØªÙ… Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡',\n        'tabs.create': 'ðŸŽ¬ Ø¥Ù†Ø´Ø§Ø¡',\n        'tabs.gallery': 'ðŸŽžï¸ Ø§Ù„Ù…Ø¹Ø±Ø¶',\n        'tabs.about': 'â„¹ï¸ Ø­ÙˆÙ„',\n        'about.content': '''\n## Ø­ÙˆÙ„ NanoTik\n\nNanoTik Ù‡Ùˆ Ù…ÙˆÙ„Ø¯ ÙÙŠØ¯ÙŠÙˆ Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠØ³ØªØ®Ø¯Ù… Ø£Ø­Ø¯Ø« Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‚Ø§Ø·Ø¹ ÙÙŠØ¯ÙŠÙˆ Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ù…Ù† Ù…Ø·Ø§Ù„Ø¨Ø§Øª Ù†ØµÙŠØ© Ø¨Ø³ÙŠØ·Ø©.\n\n### ÙƒÙŠÙ ÙŠØ¹Ù…Ù„\n1. **Ø§Ø®ØªØ± Ù…ÙˆØ¶ÙˆØ¹Ù‹Ø§**: Ø£Ø®Ø¨Ø±Ù†Ø§ Ø¹Ù…Ø§ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø¹Ù„ÙŠÙ‡ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ\n2. **Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Øµ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ**: ÙŠÙ†Ø´Ø¦ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ø¯ÙŠÙ†Ø§ Ù†ØµÙ‹Ø§ Ø¬Ø°Ø§Ø¨Ù‹Ø§\n3. **Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ø¢Ù„ÙŠ**: Ù†Ù†Ø´Ø¦ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© ÙˆÙ†Ø¬Ø¯ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ ÙˆÙ†Ø±ÙƒØ¨ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ\n4. **Ø§Ù„ØªÙ†Ø²ÙŠÙ„ ÙˆØ§Ù„Ù…Ø´Ø§Ø±ÙƒØ©**: Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ ÙÙŠ Ø¯Ù‚Ø§Ø¦Ù‚\n        ''',\n        'about.features': 'âœ¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª',\n        'about.feature1': 'ðŸ¤– Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ',\n        'about.feature2': 'ðŸ’° Ù…Ø¯ÙÙˆØ¹Ø§Øª ÙÙˆØ±ÙŠØ© Ø¨Ø¹Ù…Ù„Ø© Ù†Ø§Ù†Ùˆ Ø§Ù„Ù…Ø´ÙØ±Ø©',\n        'about.feature3': 'ðŸŒ Ø¯Ø¹Ù… Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª (Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©ØŒ Ø§Ù„ØµÙŠÙ†ÙŠØ©ØŒ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)',\n        'about.feature4': 'ðŸ“± ØªØµÙ…ÙŠÙ… Ù…ØªØ¬Ø§ÙˆØ¨ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¬Ù‡Ø²Ø©',\n        'about.feature5': 'ðŸŽ¨ Ø¥Ø®Ø±Ø§Ø¬ Ø¨Ø¬ÙˆØ¯Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ©',\n        'footer.text': 'Â© 2025 NanoTik - Ø¨ÙÙ†ÙŠ Ø¨Ù€â¤ï¸ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Streamlit'\n    }\n}\n\n_current_language = 'en'\n\n\ndef get_text(key: str, language: str | None = None) -> str:\n    \"\"\"\n    Get translated text for a given key\n    \n    Args:\n        key: Translation key in dot notation (e.g., 'app.subtitle')\n        language: Language code (defaults to current language)\n    \n    Returns:\n        Translated text or the key if not found\n    \"\"\"\n    lang = language if language is not None else _current_language\n    \n    if lang not in TRANSLATIONS:\n        lang = 'en'\n    \n    return TRANSLATIONS[lang].get(key, key)\n\n\ndef set_language(language: str):\n    \"\"\"Set the current application language\"\"\"\n    global _current_language\n    if language in SUPPORTED_LANGUAGES:\n        _current_language = language\n","size_bytes":12062}},"version":1}