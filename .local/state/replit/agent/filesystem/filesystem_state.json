{"file_contents":{"README.md":{"content":"# 🎬 NanoTik - AI Video Generator\n\n**Enhanced MoneyPrinterTurbo with Nano Cryptocurrency Payments**\n\nNanoTik is an AI-powered video generator that creates professional videos from simple text prompts, with integrated Nano cryptocurrency payment system.\n\n## ✨ Features\n\n- 🤖 **AI-Powered Video Generation** - Create professional videos from text prompts\n- 💰 **Nano Payments** - Instant, fee-less cryptocurrency transactions\n- 🌍 **Multi-Language Support** - English, Chinese (简体中文), and Arabic (العربية)\n- 📱 **Responsive Design** - Works on all devices and screen sizes\n- 🎨 **Modern UI** - Beautiful Streamlit interface with professional styling\n\n## 🚀 Quick Start\n\n### Prerequisites\n\n- Python 3.9 or higher\n- Required API keys (see Configuration section)\n\n### Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/dhyabi2/NanoTik.git\ncd NanoTik\n","size_bytes":901},"app.py":{"content":"import sys\nimport os\n\nsys.path.insert(0, os.path.dirname(__file__))\n\nexec(open('webui/NanoTik.py').read())\n","size_bytes":107},"config.example.toml":{"content":"# NanoTik Configuration File\n# Copy this file to config.toml and fill in your API keys\n\n[app]\n# LLM Provider Selection\n# Options: \"openai\", \"deepseek\", \"moonshot\"\nllm_provider = \"openai\"\n\n# OpenAI Configuration\nopenai_api_key = \"\"\nopenai_base_url = \"https://api.openai.com/v1\"\nopenai_model_name = \"gpt-4\"\n\n# DeepSeek Configuration\ndeepseek_api_key = \"\"\n\n# Moonshot Configuration\nmoonshot_api_key = \"\"\n\n# Video Source API Keys\npexels_api_keys = []\npixabay_api_keys = []\n\n[azure]\n# Azure Speech Services\nspeech_key = \"\"\nspeech_region = \"eastus\"\n\n[video]\n# Video Generation Settings\noutput_dir = \"./output\"\ntemp_dir = \"./temp\"\nmax_duration = 180\ndefault_resolution = \"1920x1080\"\n\n[payment]\n# Nano Payment Configuration\nnano_mcp_url = \"https://nano-mcp.replit.app\"\nnano_wallet_address = \"\"\n","size_bytes":786},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"azure-cognitiveservices-speech>=1.46.0\",\n    \"imageio>=2.37.0\",\n    \"imageio-ffmpeg>=0.6.0\",\n    \"moviepy>=2.2.1\",\n    \"numpy>=2.3.3\",\n    \"openai>=2.0.0\",\n    \"pexels-api>=1.0.1\",\n    \"pillow>=11.3.0\",\n    \"psycopg2-binary>=2.9.10\",\n    \"requests>=2.32.5\",\n    \"sqlalchemy>=2.0.43\",\n    \"streamlit>=1.50.0\",\n    \"toml>=0.10.2\",\n]\n","size_bytes":478},"replit.md":{"content":"# NanoTik - AI Video Generator\n\n## Overview\n\nNanoTik is an AI-powered video generation platform that creates professional videos from text prompts, integrated with Nano cryptocurrency payments. The application combines multiple AI services (LLM for script generation, Azure Speech for voiceovers, Pexels for video clips) with a cryptocurrency payment system to deliver a complete video production solution. Built with Python and Streamlit, it offers a multi-language web interface supporting English, Chinese, and Arabic.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## System Architecture\n\n### Frontend Architecture\n- **Framework**: Streamlit web application with responsive design\n- **UI Components**: Wide layout with expandable sidebar for navigation and payment controls\n- **State Management**: Streamlit session state for user sessions, credits, language preferences, and transaction history\n- **Internationalization**: Custom i18n utility supporting 3 languages (English, Chinese, Arabic) with translation dictionaries\n\n**Rationale**: Streamlit provides rapid development of data-driven applications with minimal frontend code. The session state approach keeps user data persistent across interactions without requiring complex state management libraries.\n\n### Backend Architecture\n- **Application Structure**: Modular service-oriented architecture with separated concerns:\n  - `services/`: Business logic (LLM, Payment, Video services)\n  - `models/`: Data models (UserSession)\n  - `utils/`: Helper functions (i18n)\n- **Configuration**: TOML-based config with environment variable overrides (priority: env vars > config.toml > config.example.toml)\n- **Video Processing Pipeline**: Multi-stage workflow:\n  1. Script generation via LLM\n  2. Voiceover synthesis with Azure Speech\n  3. Video clip sourcing from Pexels\n  4. Final composition with MoviePy\n\n**Rationale**: Service-oriented design allows independent scaling and testing of components. The pipeline architecture enables monitoring and failure recovery at each stage of video generation.\n\n### Data Storage\n- **Database**: PostgreSQL with psycopg2 driver\n- **Schema Design**:\n  - `users`: Tracks user sessions, credits, and activity timestamps\n  - `videos`: Stores generated video metadata with foreign key to users\n- **Connection Pattern**: Context manager pattern for automatic connection cleanup\n- **Initialization**: Automatic table creation on first database connection\n\n**Rationale**: PostgreSQL provides ACID compliance for payment and credit transactions. The foreign key relationship ensures referential integrity between users and their videos.\n\n### Authentication & Authorization\n- **Session Management**: UUID-based session IDs stored in Streamlit session state\n- **User Tracking**: Anonymous sessions linked to database users via session_id\n- **Credit System**: Integer-based credits stored in database, checked before video generation\n\n**Rationale**: Anonymous session approach eliminates registration friction while maintaining user state. Database-backed credits ensure consistency even if session state is lost.\n\n### AI/LLM Integration\n- **Multi-Provider Support**: Pluggable LLM architecture supporting:\n  - OpenAI (GPT-4)\n  - DeepSeek\n  - Moonshot AI\n- **Provider Selection**: Configuration-driven provider switching via environment variables\n- **Client Initialization**: Unified OpenAI client interface with provider-specific base URLs\n\n**Rationale**: Multi-provider approach prevents vendor lock-in and allows cost optimization by switching between providers based on pricing and availability.\n\n### Video Generation Architecture\n- **Script Generation**: LLM service creates structured scripts based on topic and duration\n- **Voiceover Synthesis**: Azure Cognitive Services Speech SDK for text-to-speech\n- **Video Sourcing**: Pexels API integration for stock video clips\n- **Composition**: MoviePy for video editing, effects, and final rendering\n- **Quality Tiers**: Three-tier system (Basic/HD/Premium) with different credit costs\n\n**Rationale**: Azure Speech provides high-quality multilingual voices. Pexels offers free stock footage. MoviePy enables programmatic video editing without external dependencies.\n\n### Payment System\n- **Cryptocurrency**: Nano cryptocurrency for instant, fee-less transactions\n- **Payment Flow**: UUID-based payment requests with address generation\n- **Credit Conversion**: Direct mapping of NANO amounts to credit values\n- **Transaction Tracking**: Payment IDs linked to user sessions for audit trail\n\n**Rationale**: Nano eliminates transaction fees and provides instant settlement, crucial for micropayments. The simulated payment flow structure allows easy integration with actual Nano MCP server.\n\n## External Dependencies\n\n### Third-Party APIs\n- **OpenAI API**: LLM for script generation (supports custom base URLs for compatible providers)\n- **DeepSeek API**: Alternative LLM provider (base URL: https://api.deepseek.com/v1)\n- **Moonshot API**: Alternative LLM provider (base URL: https://api.moonshot.cn/v1)\n- **Azure Cognitive Services**: Speech synthesis API (configurable region)\n- **Pexels API**: Stock video footage (supports multiple API keys for rate limiting)\n- **Nano MCP Server**: Cryptocurrency payment processing (environment: NANO_MCP_URL)\n\n### Python Libraries\n- **streamlit**: Web application framework\n- **psycopg2**: PostgreSQL database driver with RealDictCursor support\n- **openai**: Unified client for multiple LLM providers\n- **azure-cognitiveservices-speech**: Azure Speech SDK\n- **pexels-api**: Pexels video search client\n- **moviepy**: Video editing and composition\n- **toml**: Configuration file parsing\n\n### Database\n- **PostgreSQL**: Primary data store accessed via DATABASE_URL environment variable\n- **Schema**: Auto-created tables for users and videos with timestamp tracking\n- **Connection Pooling**: Not implemented (uses direct connections with context managers)\n\n### Environment Configuration\n- Required environment variables:\n  - `DATABASE_URL`: PostgreSQL connection string\n  - `OPENAI_API_KEY`, `DEEPSEEK_API_KEY`, `MOONSHOT_API_KEY`: LLM provider keys\n  - `AZURE_SPEECH_KEY`, `AZURE_SPEECH_REGION`: Azure Speech credentials\n  - `PEXELS_API_KEYS`: Comma-separated list of Pexels API keys\n  - `NANO_MCP_URL`, `NANO_WALLET_ADDRESS`: Nano payment configuration\n  - `LLM_PROVIDER`: Provider selection (openai/deepseek/moonshot)\n\n### File System Dependencies\n- **Output Directories**: Configurable paths for generated videos and temporary files\n- **Video Storage**: Local filesystem storage with path references in database\n- **Temp Files**: Automatic cleanup not implemented (manual temp directory management)","size_bytes":6700},"app/__init__.py":{"content":"\"\"\"\nNanoTik Application Package\n\"\"\"\n\n__version__ = \"1.0.0\"\n__author__ = \"NanoTik Team\"\n","size_bytes":87},"app/config.py":{"content":"\"\"\"\nConfiguration management for NanoTik\nLoads settings from environment variables and config files\n\"\"\"\n\nimport os\nimport toml\nfrom pathlib import Path\nfrom typing import Dict, Any\n\n\ndef load_config() -> Dict[str, Any]:\n    \"\"\"\n    Load configuration from environment variables and config file\n    Priority: Environment variables > config.toml > config.example.toml\n    \"\"\"\n    config = {}\n    \n    # Try to load from config.toml first\n    config_path = Path('config.toml')\n    example_config_path = Path('config.example.toml')\n    \n    if config_path.exists():\n        with open(config_path, 'r', encoding='utf-8') as f:\n            config = toml.load(f)\n    elif example_config_path.exists():\n        with open(example_config_path, 'r', encoding='utf-8') as f:\n            config = toml.load(f)\n    \n    # Override with environment variables\n    config['app'] = config.get('app', {})\n    config['azure'] = config.get('azure', {})\n    config['video'] = config.get('video', {})\n    config['payment'] = config.get('payment', {})\n    \n    # LLM Configuration\n    config['app']['llm_provider'] = os.getenv('LLM_PROVIDER', config['app'].get('llm_provider', 'openai'))\n    config['app']['openai_api_key'] = os.getenv('OPENAI_API_KEY', config['app'].get('openai_api_key', ''))\n    config['app']['deepseek_api_key'] = os.getenv('DEEPSEEK_API_KEY', config['app'].get('deepseek_api_key', ''))\n    config['app']['moonshot_api_key'] = os.getenv('MOONSHOT_API_KEY', config['app'].get('moonshot_api_key', ''))\n    config['app']['openai_base_url'] = os.getenv('OPENAI_BASE_URL', config['app'].get('openai_base_url', 'https://api.openai.com/v1'))\n    config['app']['openai_model_name'] = os.getenv('OPENAI_MODEL_NAME', config['app'].get('openai_model_name', 'gpt-4'))\n    \n    # Azure Speech Configuration\n    config['azure']['speech_key'] = os.getenv('AZURE_SPEECH_KEY', config['azure'].get('speech_key', ''))\n    config['azure']['speech_region'] = os.getenv('AZURE_SPEECH_REGION', config['azure'].get('speech_region', 'eastus'))\n    \n    # Video Source Configuration\n    pexels_keys = os.getenv('PEXELS_API_KEYS', '')\n    if pexels_keys:\n        config['app']['pexels_api_keys'] = pexels_keys.split(',')\n    else:\n        config['app']['pexels_api_keys'] = config['app'].get('pexels_api_keys', [])\n    \n    pixabay_keys = os.getenv('PIXABAY_API_KEYS', '')\n    if pixabay_keys:\n        config['app']['pixabay_api_keys'] = pixabay_keys.split(',')\n    else:\n        config['app']['pixabay_api_keys'] = config['app'].get('pixabay_api_keys', [])\n    \n    # Payment Configuration\n    config['payment']['nano_mcp_url'] = os.getenv('NANO_MCP_URL', config['payment'].get('nano_mcp_url', 'https://nano-mcp.replit.app'))\n    config['payment']['nano_wallet_address'] = os.getenv('NANO_WALLET_ADDRESS', config['payment'].get('nano_wallet_address', ''))\n    \n    # Video Configuration\n    config['video']['output_dir'] = os.getenv('VIDEO_OUTPUT_DIR', config['video'].get('output_dir', './output'))\n    config['video']['temp_dir'] = os.getenv('VIDEO_TEMP_DIR', config['video'].get('temp_dir', './temp'))\n    config['video']['max_duration'] = int(os.getenv('VIDEO_MAX_DURATION', config['video'].get('max_duration', 180)))\n    config['video']['default_resolution'] = os.getenv('VIDEO_DEFAULT_RESOLUTION', config['video'].get('default_resolution', '1920x1080'))\n    \n    return config\n\n\ndef get_config_value(key: str, default: Any = None) -> Any:\n    \"\"\"\n    Get a configuration value by key with dot notation\n    Example: get_config_value('app.openai_api_key')\n    \"\"\"\n    config = load_config()\n    keys = key.split('.')\n    value = config\n    \n    for k in keys:\n        if isinstance(value, dict):\n            value = value.get(k)\n        else:\n            return default\n    \n    return value if value is not None else default\n\n\ndef validate_config() -> tuple[bool, list[str]]:\n    \"\"\"\n    Validate that required configuration is present\n    Returns: (is_valid, list_of_errors)\n    \"\"\"\n    config = load_config()\n    errors = []\n    \n    # Check LLM API keys\n    llm_provider = config['app'].get('llm_provider', 'openai')\n    if llm_provider == 'openai' and not config['app'].get('openai_api_key'):\n        errors.append(\"OpenAI API key is required when using OpenAI as LLM provider\")\n    elif llm_provider == 'deepseek' and not config['app'].get('deepseek_api_key'):\n        errors.append(\"DeepSeek API key is required when using DeepSeek as LLM provider\")\n    \n    # Check video source API keys\n    if not config['app'].get('pexels_api_keys') and not config['app'].get('pixabay_api_keys'):\n        errors.append(\"At least one video source API key (Pexels or Pixabay) is required\")\n    \n    # Check Azure Speech key for voice synthesis\n    if not config['azure'].get('speech_key'):\n        errors.append(\"Azure Speech API key is required for voice synthesis\")\n    \n    return len(errors) == 0, errors\n","size_bytes":4876},"app/database.py":{"content":"\"\"\"\nDatabase module for NanoTik\nHandles PostgreSQL connections and operations\n\"\"\"\n\nimport os\nimport psycopg2\nfrom psycopg2.extras import RealDictCursor\nfrom typing import Dict, Any, List, Optional\nfrom datetime import datetime\nimport uuid\n\n\nclass Database:\n    \"\"\"Database connection and operations manager\"\"\"\n    \n    def __init__(self):\n        self.database_url = os.getenv('DATABASE_URL')\n        if not self.database_url:\n            raise Exception(\"DATABASE_URL not configured\")\n        self._ensure_tables()\n    \n    def get_connection(self):\n        \"\"\"Get a database connection\"\"\"\n        return psycopg2.connect(self.database_url)\n    \n    def _ensure_tables(self):\n        \"\"\"Create tables if they don't exist\"\"\"\n        with self.get_connection() as conn:\n            with conn.cursor() as cur:\n                # Users table\n                cur.execute(\"\"\"\n                    CREATE TABLE IF NOT EXISTS users (\n                        id VARCHAR(36) PRIMARY KEY,\n                        session_id VARCHAR(36) UNIQUE NOT NULL,\n                        credits INTEGER DEFAULT 0,\n                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                        last_active TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n                    )\n                \"\"\")\n                \n                # Videos table\n                cur.execute(\"\"\"\n                    CREATE TABLE IF NOT EXISTS videos (\n                        id VARCHAR(36) PRIMARY KEY,\n                        user_id VARCHAR(36) REFERENCES users(id),\n                        title VARCHAR(255) NOT NULL,\n                        topic TEXT NOT NULL,\n                        file_path TEXT NOT NULL,\n                        duration INTEGER,\n                        quality VARCHAR(50),\n                        language VARCHAR(10),\n                        status VARCHAR(50) DEFAULT 'completed',\n                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n                    )\n                \"\"\")\n                \n                # Transactions table\n                cur.execute(\"\"\"\n                    CREATE TABLE IF NOT EXISTS transactions (\n                        id VARCHAR(36) PRIMARY KEY,\n                        user_id VARCHAR(36) REFERENCES users(id),\n                        transaction_type VARCHAR(50) NOT NULL,\n                        amount NUMERIC(38, 18),\n                        credits INTEGER NOT NULL,\n                        currency VARCHAR(10),\n                        payment_id VARCHAR(100) UNIQUE,\n                        status VARCHAR(50) DEFAULT 'pending',\n                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                        completed_at TIMESTAMP\n                    )\n                \"\"\")\n                \n                # Create indexes for better query performance\n                cur.execute(\"\"\"\n                    CREATE INDEX IF NOT EXISTS idx_videos_user_id ON videos(user_id)\n                \"\"\")\n                cur.execute(\"\"\"\n                    CREATE INDEX IF NOT EXISTS idx_transactions_user_id ON transactions(user_id)\n                \"\"\")\n                cur.execute(\"\"\"\n                    CREATE INDEX IF NOT EXISTS idx_transactions_payment_id ON transactions(payment_id)\n                \"\"\")\n                \n                conn.commit()\n    \n    def create_user(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Create a new user\"\"\"\n        user_id = str(uuid.uuid4())\n        \n        with self.get_connection() as conn:\n            with conn.cursor(cursor_factory=RealDictCursor) as cur:\n                cur.execute(\"\"\"\n                    INSERT INTO users (id, session_id, credits)\n                    VALUES (%s, %s, 0)\n                    RETURNING *\n                \"\"\", (user_id, session_id))\n                \n                conn.commit()\n                return dict(cur.fetchone())\n    \n    def get_user_by_session(self, session_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Get user by session ID\"\"\"\n        with self.get_connection() as conn:\n            with conn.cursor(cursor_factory=RealDictCursor) as cur:\n                cur.execute(\"\"\"\n                    SELECT * FROM users WHERE session_id = %s\n                \"\"\", (session_id,))\n                \n                result = cur.fetchone()\n                return dict(result) if result else None\n    \n    def update_user_credits(self, user_id: str, credits: int) -> bool:\n        \"\"\"Update user's credit balance\"\"\"\n        with self.get_connection() as conn:\n            with conn.cursor() as cur:\n                cur.execute(\"\"\"\n                    UPDATE users SET credits = %s, last_active = CURRENT_TIMESTAMP\n                    WHERE id = %s\n                \"\"\", (credits, user_id))\n                \n                conn.commit()\n                return cur.rowcount > 0\n    \n    def add_credits(self, user_id: str, amount: int) -> int:\n        \"\"\"Add credits to user and return new balance\"\"\"\n        with self.get_connection() as conn:\n            with conn.cursor() as cur:\n                cur.execute(\"\"\"\n                    UPDATE users SET credits = credits + %s, last_active = CURRENT_TIMESTAMP\n                    WHERE id = %s\n                    RETURNING credits\n                \"\"\", (amount, user_id))\n                \n                conn.commit()\n                result = cur.fetchone()\n                return result[0] if result else 0\n    \n    def deduct_credits(self, user_id: str, amount: int) -> bool:\n        \"\"\"Deduct credits from user if sufficient balance\"\"\"\n        with self.get_connection() as conn:\n            with conn.cursor() as cur:\n                cur.execute(\"\"\"\n                    UPDATE users SET credits = credits - %s, last_active = CURRENT_TIMESTAMP\n                    WHERE id = %s AND credits >= %s\n                    RETURNING credits\n                \"\"\", (amount, user_id, amount))\n                \n                conn.commit()\n                return cur.rowcount > 0\n    \n    def create_video(self, user_id: str, video_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Create a video record\"\"\"\n        video_id = str(uuid.uuid4())\n        \n        with self.get_connection() as conn:\n            with conn.cursor(cursor_factory=RealDictCursor) as cur:\n                cur.execute(\"\"\"\n                    INSERT INTO videos (id, user_id, title, topic, file_path, duration, quality, language, status)\n                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n                    RETURNING *\n                \"\"\", (\n                    video_id,\n                    user_id,\n                    video_data.get('title', ''),\n                    video_data.get('topic', ''),\n                    video_data.get('file_path', ''),\n                    video_data.get('duration', 0),\n                    video_data.get('quality', 'basic'),\n                    video_data.get('language', 'en'),\n                    video_data.get('status', 'completed')\n                ))\n                \n                conn.commit()\n                return dict(cur.fetchone())\n    \n    def get_user_videos(self, user_id: str, limit: int = 50) -> List[Dict[str, Any]]:\n        \"\"\"Get all videos for a user\"\"\"\n        with self.get_connection() as conn:\n            with conn.cursor(cursor_factory=RealDictCursor) as cur:\n                cur.execute(\"\"\"\n                    SELECT * FROM videos\n                    WHERE user_id = %s\n                    ORDER BY created_at DESC\n                    LIMIT %s\n                \"\"\", (user_id, limit))\n                \n                return [dict(row) for row in cur.fetchall()]\n    \n    def create_transaction(self, user_id: str, transaction_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Create a transaction record\"\"\"\n        transaction_id = str(uuid.uuid4())\n        \n        with self.get_connection() as conn:\n            with conn.cursor(cursor_factory=RealDictCursor) as cur:\n                cur.execute(\"\"\"\n                    INSERT INTO transactions (id, user_id, transaction_type, amount, credits, currency, payment_id, status)\n                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n                    RETURNING *\n                \"\"\", (\n                    transaction_id,\n                    user_id,\n                    transaction_data.get('transaction_type', 'purchase'),\n                    transaction_data.get('amount', 0),\n                    transaction_data.get('credits', 0),\n                    transaction_data.get('currency', 'NANO'),\n                    transaction_data.get('payment_id', ''),\n                    transaction_data.get('status', 'pending')\n                ))\n                \n                conn.commit()\n                return dict(cur.fetchone())\n    \n    def update_transaction_status(self, transaction_id: str, status: str) -> bool:\n        \"\"\"Update transaction status\"\"\"\n        with self.get_connection() as conn:\n            with conn.cursor() as cur:\n                cur.execute(\"\"\"\n                    UPDATE transactions \n                    SET status = %s, completed_at = CURRENT_TIMESTAMP\n                    WHERE id = %s\n                \"\"\", (status, transaction_id))\n                \n                conn.commit()\n                return cur.rowcount > 0\n    \n    def get_user_transactions(self, user_id: str, limit: int = 50) -> List[Dict[str, Any]]:\n        \"\"\"Get transaction history for a user\"\"\"\n        with self.get_connection() as conn:\n            with conn.cursor(cursor_factory=RealDictCursor) as cur:\n                cur.execute(\"\"\"\n                    SELECT * FROM transactions\n                    WHERE user_id = %s\n                    ORDER BY created_at DESC\n                    LIMIT %s\n                \"\"\", (user_id, limit))\n                \n                return [dict(row) for row in cur.fetchall()]\n\n\n# Global database instance\n_db_instance = None\n\ndef get_database() -> Database:\n    \"\"\"Get or create the global database instance\"\"\"\n    global _db_instance\n    if _db_instance is None:\n        _db_instance = Database()\n    return _db_instance\n","size_bytes":10071},"webui/NanoTik.py":{"content":"\"\"\"\nNanoTik - AI Video Generator with Nano Cryptocurrency Payments\nEnhanced version of MoneyPrinterTurbo with modern UI and payment integration\n\"\"\"\n\nimport streamlit as st\nimport os\nimport sys\nfrom pathlib import Path\n\n# Add parent directory to path\nsys.path.insert(0, str(Path(__file__).parent.parent))\n\nfrom app.config import load_config\nfrom app.utils.i18n import get_text, set_language, SUPPORTED_LANGUAGES\nfrom app.services.payment_service import PaymentService\nfrom app.services.video_service import VideoService\nfrom app.models.user import UserSession\nfrom app.database import get_database\n\n# Page configuration\nst.set_page_config(\n    page_title=\"NanoTik - AI Video Generator\",\n    page_icon=\"🎬\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\"\n)\n\n# Initialize database\ndb = get_database()\n\n# Initialize session state\nif 'user_session' not in st.session_state:\n    st.session_state.user_session = UserSession()\n    # Get or create user in database\n    db_user = db.get_user_by_session(st.session_state.user_session.session_id)\n    if not db_user:\n        db_user = db.create_user(st.session_state.user_session.session_id)\n    st.session_state.user_id = db_user['id']\n    st.session_state.credits = db_user['credits']\n\nif 'language' not in st.session_state:\n    st.session_state.language = 'en'\n\nif 'credits' not in st.session_state:\n    st.session_state.credits = 0\n\n# Load configuration\nconfig = load_config()\n\n# Initialize services\npayment_service = PaymentService()\nvideo_service = VideoService(config)\n\n\ndef render_header():\n    \"\"\"Render the application header with language selector\"\"\"\n    col1, col2, col3 = st.columns([3, 1, 1])\n    \n    with col1:\n        st.title(\"🎬 NanoTik\")\n        st.caption(get_text('app.subtitle', st.session_state.language))\n    \n    with col2:\n        st.metric(\n            label=get_text('credits.balance', st.session_state.language),\n            value=st.session_state.credits\n        )\n    \n    with col3:\n        language = st.selectbox(\n            get_text('language.select', st.session_state.language),\n            options=list(SUPPORTED_LANGUAGES.keys()),\n            format_func=lambda x: SUPPORTED_LANGUAGES[x],\n            key='language_selector'\n        )\n        if language != st.session_state.language:\n            st.session_state.language = language\n            set_language(language)\n            st.rerun()\n\n\ndef render_sidebar():\n    \"\"\"Render the sidebar with credit packages and payment options\"\"\"\n    with st.sidebar:\n        st.header(get_text('credits.buy', st.session_state.language))\n        \n        # Credit packages\n        packages = [\n            {\"credits\": 10, \"price\": 0.1, \"bonus\": 0, \"popular\": False},\n            {\"credits\": 50, \"price\": 0.4, \"bonus\": 5, \"popular\": True},\n            {\"credits\": 100, \"price\": 0.7, \"bonus\": 15, \"popular\": False},\n            {\"credits\": 500, \"price\": 3.0, \"bonus\": 100, \"popular\": False},\n        ]\n        \n        for pkg in packages:\n            with st.container():\n                if pkg['popular']:\n                    st.markdown(\"⭐ **POPULAR**\")\n                \n                col1, col2 = st.columns([2, 1])\n                with col1:\n                    total_credits = pkg['credits'] + pkg['bonus']\n                    st.write(f\"**{pkg['credits']} {get_text('credits.name', st.session_state.language)}**\")\n                    if pkg['bonus'] > 0:\n                        st.caption(f\"+{pkg['bonus']} {get_text('credits.bonus', st.session_state.language)}\")\n                \n                with col2:\n                    st.write(f\"{pkg['price']} NANO\")\n                \n                if st.button(\n                    get_text('credits.purchase', st.session_state.language),\n                    key=f\"buy_{pkg['credits']}\",\n                    use_container_width=True\n                ):\n                    handle_purchase(pkg['credits'], pkg['bonus'], pkg['price'])\n                \n                st.divider()\n        \n        # Info section\n        st.info(get_text('credits.info', st.session_state.language))\n        \n        # Cost breakdown\n        with st.expander(get_text('credits.costs', st.session_state.language)):\n            st.write(f\"- {get_text('video.basic', st.session_state.language)}: 1 {get_text('credits.name', st.session_state.language)}\")\n            st.write(f\"- {get_text('video.hd', st.session_state.language)}: 2 {get_text('credits.name', st.session_state.language)}\")\n            st.write(f\"- {get_text('video.premium', st.session_state.language)}: 3 {get_text('credits.name', st.session_state.language)}\")\n\n\ndef handle_purchase(credits, bonus, price):\n    \"\"\"Handle credit purchase with Nano payment\"\"\"\n    with st.spinner(get_text('payment.processing', st.session_state.language)):\n        try:\n            # Generate payment request\n            payment_result = payment_service.create_payment_request(\n                amount=price,\n                credits=credits + bonus,\n                user_id=st.session_state.user_id\n            )\n            \n            if payment_result['success']:\n                # Add credits to database\n                total_credits = credits + bonus\n                new_balance = db.add_credits(st.session_state.user_id, total_credits)\n                st.session_state.credits = new_balance\n                \n                st.success(get_text('payment.success', st.session_state.language))\n                st.rerun()\n            else:\n                st.error(get_text('payment.failed', st.session_state.language))\n        except Exception as e:\n            st.error(f\"{get_text('payment.error', st.session_state.language)}: {str(e)}\")\n\n\ndef render_video_generator():\n    \"\"\"Render the main video generation interface\"\"\"\n    st.header(get_text('video.generate', st.session_state.language))\n    \n    # Check credits\n    if st.session_state.credits < 1:\n        st.warning(get_text('credits.insufficient', st.session_state.language))\n        st.info(get_text('credits.buy_prompt', st.session_state.language))\n        return\n    \n    # Video generation form\n    with st.form(\"video_generator\"):\n        # Topic input\n        topic = st.text_input(\n            get_text('video.topic', st.session_state.language),\n            placeholder=get_text('video.topic_placeholder', st.session_state.language)\n        )\n        \n        col1, col2 = st.columns(2)\n        \n        with col1:\n            # Quality selection\n            quality = st.selectbox(\n                get_text('video.quality', st.session_state.language),\n                options=['basic', 'hd', 'premium'],\n                format_func=lambda x: get_text(f'video.{x}', st.session_state.language)\n            )\n        \n        with col2:\n            # Duration selection\n            duration = st.slider(\n                get_text('video.duration', st.session_state.language),\n                min_value=15,\n                max_value=180,\n                value=60,\n                step=15\n            )\n        \n        # Advanced options\n        with st.expander(get_text('video.advanced', st.session_state.language)):\n            col1, col2 = st.columns(2)\n            \n            with col1:\n                voice = st.selectbox(\n                    get_text('video.voice', st.session_state.language),\n                    options=['male', 'female', 'neutral']\n                )\n            \n            with col2:\n                music = st.checkbox(\n                    get_text('video.music', st.session_state.language),\n                    value=True\n                )\n            \n            subtitle_position = st.selectbox(\n                get_text('video.subtitle_position', st.session_state.language),\n                options=['bottom', 'top', 'center']\n            )\n        \n        # Submit button\n        submitted = st.form_submit_button(\n            get_text('video.create', st.session_state.language),\n            use_container_width=True\n        )\n        \n        if submitted:\n            if not topic:\n                st.error(get_text('video.topic_required', st.session_state.language))\n            else:\n                generate_video(topic, quality, duration, voice, music, subtitle_position)\n\n\ndef generate_video(topic, quality, duration, voice, music, subtitle_position):\n    \"\"\"Generate video based on user input\"\"\"\n    # Calculate credit cost\n    cost_map = {'basic': 1, 'hd': 2, 'premium': 3}\n    cost = cost_map[quality]\n    \n    if st.session_state.credits < cost:\n        st.error(get_text('credits.insufficient', st.session_state.language))\n        return\n    \n    # Progress tracking\n    progress_bar = st.progress(0)\n    status_text = st.empty()\n    \n    try:\n        # Step 1: Generate script\n        status_text.text(get_text('video.generating_script', st.session_state.language))\n        progress_bar.progress(20)\n        \n        script = video_service.generate_script(topic, duration, st.session_state.language)\n        \n        # Step 2: Generate voiceover\n        status_text.text(get_text('video.generating_voice', st.session_state.language))\n        progress_bar.progress(40)\n        \n        audio_path = video_service.generate_voiceover(script, voice, st.session_state.language)\n        \n        # Step 3: Search for video clips\n        status_text.text(get_text('video.searching_clips', st.session_state.language))\n        progress_bar.progress(60)\n        \n        clips = video_service.search_video_clips(script)\n        \n        # Step 4: Compose video\n        status_text.text(get_text('video.composing', st.session_state.language))\n        progress_bar.progress(80)\n        \n        video_path = video_service.compose_video(\n            clips=clips,\n            audio_path=audio_path,\n            script=script,\n            subtitle_position=subtitle_position,\n            quality=quality,\n            music=music\n        )\n        \n        # Step 5: Finalize\n        progress_bar.progress(100)\n        status_text.text(get_text('video.complete', st.session_state.language))\n        \n        # Deduct credits from database\n        if db.deduct_credits(st.session_state.user_id, cost):\n            st.session_state.credits -= cost\n            \n            # Save video to database\n            video_record = db.create_video(st.session_state.user_id, {\n                'title': topic[:100],\n                'topic': topic,\n                'file_path': video_path,\n                'duration': duration,\n                'quality': quality,\n                'language': st.session_state.language,\n                'status': 'completed'\n            })\n            \n            # Display result\n            st.success(get_text('video.success', st.session_state.language))\n            \n            if os.path.exists(video_path):\n                st.video(video_path)\n                \n                with open(video_path, 'rb') as f:\n                    st.download_button(\n                        label=get_text('video.download', st.session_state.language),\n                        data=f,\n                        file_name=f\"nanotik_{topic[:20]}.mp4\",\n                        mime=\"video/mp4\"\n                    )\n        else:\n            st.error(get_text('credits.insufficient', st.session_state.language))\n        \n    except Exception as e:\n        st.error(f\"{get_text('video.error', st.session_state.language)}: {str(e)}\")\n        status_text.text(\"\")\n        progress_bar.empty()\n\n\ndef render_gallery():\n    \"\"\"Render user's video gallery from database\"\"\"\n    st.header(get_text('gallery.title', st.session_state.language))\n    \n    videos = db.get_user_videos(st.session_state.user_id, limit=30)\n    \n    if not videos:\n        st.info(get_text('gallery.empty', st.session_state.language))\n        return\n    \n    cols = st.columns(3)\n    for idx, video in enumerate(videos):\n        with cols[idx % 3]:\n            if os.path.exists(video['file_path']):\n                st.video(video['file_path'])\n                st.caption(video['title'])\n                st.caption(f\"{get_text('gallery.created', st.session_state.language)}: {video['created_at'].strftime('%Y-%m-%d %H:%M')}\")\n\n\ndef main():\n    \"\"\"Main application entry point\"\"\"\n    render_header()\n    render_sidebar()\n    \n    # Main content tabs\n    tab1, tab2, tab3 = st.tabs([\n        get_text('tabs.create', st.session_state.language),\n        get_text('tabs.gallery', st.session_state.language),\n        get_text('tabs.about', st.session_state.language)\n    ])\n    \n    with tab1:\n        render_video_generator()\n    \n    with tab2:\n        render_gallery()\n    \n    with tab3:\n        st.markdown(get_text('about.content', st.session_state.language))\n        \n        # Feature list\n        st.subheader(get_text('about.features', st.session_state.language))\n        features = [\n            'about.feature1',\n            'about.feature2',\n            'about.feature3',\n            'about.feature4',\n            'about.feature5'\n        ]\n        for feature in features:\n            st.write(f\"- {get_text(feature, st.session_state.language)}\")\n    \n    # Footer\n    st.divider()\n    st.caption(get_text('footer.text', st.session_state.language))\n\n\nif __name__ == \"__main__\":\n    main()\n","size_bytes":13182},"app/models/__init__.py":{"content":"\"\"\"\nNanoTik Models Package\n\"\"\"\n\nfrom .user import UserSession\n\n__all__ = ['UserSession']\n","size_bytes":89},"app/models/user.py":{"content":"\"\"\"\nUser session and data models\n\"\"\"\n\nfrom typing import List, Dict, Any\nfrom datetime import datetime\nimport uuid\n\n\nclass UserSession:\n    \"\"\"User session model for tracking user state\"\"\"\n    \n    def __init__(self):\n        self.session_id = str(uuid.uuid4())\n        self.created_at = datetime.utcnow()\n        self.credits = 0\n        self.videos = []\n        self.transactions = []\n    \n    def add_credits(self, amount: int):\n        \"\"\"Add credits to user account\"\"\"\n        self.credits += amount\n    \n    def deduct_credits(self, amount: int) -> bool:\n        \"\"\"\n        Deduct credits from user account\n        Returns True if successful, False if insufficient credits\n        \"\"\"\n        if self.credits >= amount:\n            self.credits -= amount\n            return True\n        return False\n    \n    def add_video(self, video_data: Dict[str, Any]):\n        \"\"\"Add a generated video to user's gallery\"\"\"\n        video = {\n            'id': str(uuid.uuid4()),\n            'created_at': datetime.utcnow().isoformat(),\n            **video_data\n        }\n        self.videos.append(video)\n    \n    def get_videos(self) -> List[Dict[str, Any]]:\n        \"\"\"Get all videos for this user\"\"\"\n        return self.videos\n    \n    def add_transaction(self, transaction_data: Dict[str, Any]):\n        \"\"\"Record a payment transaction\"\"\"\n        transaction = {\n            'id': str(uuid.uuid4()),\n            'timestamp': datetime.utcnow().isoformat(),\n            **transaction_data\n        }\n        self.transactions.append(transaction)\n    \n    def get_transaction_history(self) -> List[Dict[str, Any]]:\n        \"\"\"Get payment transaction history\"\"\"\n        return self.transactions\n","size_bytes":1689},"app/services/__init__.py":{"content":"\"\"\"\nNanoTik Services Package\n\"\"\"\n\nfrom .llm_service import LLMService\nfrom .payment_service import PaymentService\nfrom .video_service import VideoService\n\n__all__ = ['LLMService', 'PaymentService', 'VideoService']\n","size_bytes":214},"app/services/llm_service.py":{"content":"\"\"\"\nLLM Service for script generation\nSupports multiple AI providers: OpenAI, DeepSeek, Moonshot\n\"\"\"\n\nimport os\nfrom typing import Dict, Any, List\nimport openai\nfrom openai import OpenAI\n\n\nclass LLMService:\n    \"\"\"Service for interacting with Large Language Models\"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.provider = config['app'].get('llm_provider', 'openai')\n        self._initialize_client()\n    \n    def _initialize_client(self):\n        \"\"\"Initialize the appropriate LLM client based on provider\"\"\"\n        if self.provider == 'openai':\n            api_key = self.config['app'].get('openai_api_key')\n            base_url = self.config['app'].get('openai_base_url', 'https://api.openai.com/v1')\n            self.client = OpenAI(api_key=api_key, base_url=base_url)\n            self.model = self.config['app'].get('openai_model_name', 'gpt-4')\n        \n        elif self.provider == 'deepseek':\n            api_key = self.config['app'].get('deepseek_api_key')\n            self.client = OpenAI(\n                api_key=api_key,\n                base_url='https://api.deepseek.com/v1'\n            )\n            self.model = 'deepseek-chat'\n        \n        elif self.provider == 'moonshot':\n            api_key = self.config['app'].get('moonshot_api_key')\n            self.client = OpenAI(\n                api_key=api_key,\n                base_url='https://api.moonshot.cn/v1'\n            )\n            self.model = 'moonshot-v1-8k'\n        \n        else:\n            raise ValueError(f\"Unsupported LLM provider: {self.provider}\")\n    \n    def generate_script(self, topic: str, duration: int, language: str = 'en') -> Dict[str, Any]:\n        \"\"\"\n        Generate a video script based on topic and duration\n        \n        Args:\n            topic: The video topic\n            duration: Target duration in seconds\n            language: Language code (en, zh, ar)\n        \n        Returns:\n            Dictionary with script, scenes, and metadata\n        \"\"\"\n        prompt = self._build_script_prompt(topic, duration, language)\n        \n        try:\n            response = self.client.chat.completions.create(\n                model=self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": self._get_system_prompt(language)},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                temperature=0.7,\n                max_tokens=2000\n            )\n            \n            content = response.choices[0].message.content\n            if content is None:\n                raise Exception(\"No content received from LLM\")\n            return self._parse_script_response(content)\n        \n        except Exception as e:\n            raise Exception(f\"Failed to generate script: {str(e)}\")\n    \n    def _get_system_prompt(self, language: str) -> str:\n        \"\"\"Get system prompt based on language\"\"\"\n        prompts = {\n            'en': \"You are a professional video script writer. Create engaging, informative scripts for short-form videos.\",\n            'zh': \"你是一位专业的视频脚本作家。为短视频创作引人入胜、信息丰富的脚本。\",\n            'ar': \"أنت كاتب محترف لنصوص الفيديو. قم بإنشاء نصوص جذابة ومفيدة لمقاطع الفيديو القصيرة.\"\n        }\n        return prompts.get(language, prompts['en'])\n    \n    def _build_script_prompt(self, topic: str, duration: int, language: str) -> str:\n        \"\"\"Build the prompt for script generation\"\"\"\n        word_count = duration * 2  # Approximate 2 words per second\n        \n        prompts = {\n            'en': f\"\"\"Create a {duration}-second video script about: {topic}\n\nRequirements:\n- Approximately {word_count} words\n- Include 5-7 distinct scenes\n- Each scene should have a description and narration\n- Make it engaging and informative\n- Include visual suggestions for each scene\n\nFormat your response as:\nScene 1: [Visual description]\nNarration: [What to say]\n\nScene 2: [Visual description]\nNarration: [What to say]\n...\"\"\",\n            'zh': f\"\"\"创建一个{duration}秒的视频脚本，主题：{topic}\n\n要求：\n- 大约{word_count}字\n- 包含5-7个不同的场景\n- 每个场景应有描述和旁白\n- 内容引人入胜且信息丰富\n- 为每个场景提供视觉建议\n\n按以下格式回复：\n场景1：[视觉描述]\n旁白：[要说的内容]\n\n场景2：[视觉描述]\n旁白：[要说的内容]\n...\"\"\",\n            'ar': f\"\"\"أنشئ نص فيديو مدته {duration} ثانية حول: {topic}\n\nالمتطلبات:\n- حوالي {word_count} كلمة\n- يشمل 5-7 مشاهد متميزة\n- يجب أن يكون لكل مشهد وصف وسرد\n- اجعله جذابًا وغنيًا بالمعلومات\n- قدم اقتراحات بصرية لكل مشهد\n\nصيغة الرد:\nالمشهد 1: [الوصف البصري]\nالسرد: [ما يجب قوله]\n\nالمشهد 2: [الوصف البصري]\nالسرد: [ما يجب قوله]\n...\"\"\"\n        }\n        \n        return prompts.get(language, prompts['en'])\n    \n    def _parse_script_response(self, content: str) -> Dict[str, Any]:\n        \"\"\"Parse the LLM response into structured script data\"\"\"\n        scenes = []\n        current_scene = None\n        \n        lines = content.split('\\n')\n        for line in lines:\n            line = line.strip()\n            if not line:\n                continue\n            \n            # Check for scene markers in multiple languages\n            if any(marker in line.lower() for marker in ['scene', '场景', 'المشهد']):\n                if current_scene:\n                    scenes.append(current_scene)\n                current_scene = {'description': '', 'narration': ''}\n                # Extract scene description\n                if ':' in line:\n                    current_scene['description'] = line.split(':', 1)[1].strip()\n            \n            elif any(marker in line.lower() for marker in ['narration', '旁白', 'السرد']):\n                if current_scene and ':' in line:\n                    current_scene['narration'] = line.split(':', 1)[1].strip()\n        \n        # Add the last scene\n        if current_scene:\n            scenes.append(current_scene)\n        \n        # Compile full narration\n        full_narration = ' '.join([scene['narration'] for scene in scenes if scene.get('narration')])\n        \n        return {\n            'scenes': scenes,\n            'narration': full_narration,\n            'scene_count': len(scenes)\n        }\n","size_bytes":6537},"app/services/payment_service.py":{"content":"\"\"\"\nPayment Service for Nano cryptocurrency transactions\nIntegrates with NANO MCP Server for payment processing\n\"\"\"\n\nimport os\nimport requests\nfrom typing import Dict, Any\nimport uuid\nfrom datetime import datetime\n\n\nclass PaymentService:\n    \"\"\"Service for handling Nano cryptocurrency payments\"\"\"\n    \n    def __init__(self):\n        self.nano_mcp_url = os.getenv('NANO_MCP_URL', 'https://nano-mcp.replit.app')\n        self.wallet_address = os.getenv('NANO_WALLET_ADDRESS', '')\n    \n    def create_payment_request(self, amount: float, credits: int, user_id: str = None) -> Dict[str, Any]:\n        \"\"\"\n        Create a payment request for credit purchase\n        \n        Args:\n            amount: Amount in NANO\n            credits: Number of credits to purchase\n            user_id: User ID for transaction tracking (optional)\n        \n        Returns:\n            Payment request details including QR code and payment address\n        \"\"\"\n        payment_id = str(uuid.uuid4())\n        \n        try:\n            # In a real implementation, this would call the NANO MCP Server\n            # For now, we'll simulate the payment flow\n            \n            # Generate payment address (in real implementation, from MCP server)\n            payment_address = self._generate_payment_address()\n            \n            payment_request = {\n                'success': True,\n                'payment_id': payment_id,\n                'amount': amount,\n                'credits': credits,\n                'currency': 'NANO',\n                'payment_address': payment_address,\n                'created_at': datetime.utcnow().isoformat(),\n                'status': 'pending',\n                'expires_at': self._get_expiry_time(),\n                'user_id': user_id\n            }\n            \n            # Save to database if user_id provided\n            if user_id:\n                from app.database import get_database\n                db = get_database()\n                transaction = db.create_transaction(user_id, {\n                    'transaction_type': 'purchase',\n                    'amount': float(amount),  # Store as float for now\n                    'credits': credits,\n                    'currency': 'NANO',\n                    'payment_id': payment_id,\n                    'status': 'pending'  # Start as pending\n                })\n                \n                # For DEMO ONLY: Immediately mark as completed\n                # In production, this would wait for Nano MCP webhook confirmation\n                db.update_transaction_status(transaction['id'], 'completed')\n                payment_request['status'] = 'completed'\n                payment_request['transaction_id'] = transaction['id']\n            \n            return payment_request\n        \n        except Exception as e:\n            return {\n                'success': False,\n                'error': str(e)\n            }\n    \n    def verify_payment(self, payment_id: str) -> Dict[str, Any]:\n        \"\"\"\n        Verify if a payment has been completed\n        \n        Args:\n            payment_id: The payment request ID\n        \n        Returns:\n            Payment verification status\n        \"\"\"\n        try:\n            # In real implementation, check with NANO MCP Server\n            # For demo, we'll simulate successful payment after a delay\n            \n            return {\n                'success': True,\n                'payment_id': payment_id,\n                'status': 'completed',\n                'verified_at': datetime.utcnow().isoformat()\n            }\n        \n        except Exception as e:\n            return {\n                'success': False,\n                'error': str(e)\n            }\n    \n    def get_payment_status(self, payment_id: str) -> str:\n        \"\"\"\n        Get current status of a payment\n        \n        Returns: 'pending', 'completed', 'failed', 'expired'\n        \"\"\"\n        # In real implementation, query NANO MCP Server\n        return 'completed'\n    \n    def _generate_payment_address(self) -> str:\n        \"\"\"Generate or retrieve a payment address\"\"\"\n        if self.wallet_address:\n            return self.wallet_address\n        \n        # In real implementation, request from NANO MCP Server\n        return 'nano_3demo_address_for_testing_purposes_only_1234567890'\n    \n    def _get_expiry_time(self) -> str:\n        \"\"\"Get payment expiry time (15 minutes from now)\"\"\"\n        from datetime import timedelta\n        expiry = datetime.utcnow() + timedelta(minutes=15)\n        return expiry.isoformat()\n    \n    def get_transaction_history(self, user_id: str) -> list:\n        \"\"\"\n        Get payment transaction history for a user\n        \n        Args:\n            user_id: User identifier\n        \n        Returns:\n            List of transaction records\n        \"\"\"\n        # In real implementation, fetch from database\n        return []\n","size_bytes":4862},"app/services/video_service.py":{"content":"\"\"\"\nVideo Service for video generation and composition\nHandles script generation, voiceover, video clips, and final composition\n\"\"\"\n\nimport os\nfrom typing import Dict, Any, List\nfrom pathlib import Path\nimport tempfile\nimport requests\nimport azure.cognitiveservices.speech as speechsdk\nfrom pexels_api import API as PexelsAPI\nfrom moviepy import VideoFileClip, AudioFileClip, concatenate_videoclips\nfrom moviepy.video import fx as vfx\nfrom contextlib import ExitStack\nfrom .llm_service import LLMService\n\n\nclass VideoService:\n    \"\"\"Service for video generation operations\"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.llm_service = LLMService(config)\n        self.output_dir = Path(config['video'].get('output_dir', './output'))\n        self.temp_dir = Path(config['video'].get('temp_dir', './temp'))\n        \n        # Create directories\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        self.temp_dir.mkdir(parents=True, exist_ok=True)\n        \n        # Initialize Pexels API\n        pexels_keys = self.config['app'].get('pexels_api_keys', [])\n        self.pexels_api = PexelsAPI(pexels_keys[0]) if pexels_keys else None\n        \n        # Initialize Azure Speech\n        speech_key = self.config['azure'].get('speech_key', '')\n        speech_region = self.config['azure'].get('speech_region', 'eastus')\n        if speech_key:\n            self.speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n        else:\n            self.speech_config = None\n    \n    def generate_script(self, topic: str, duration: int, language: str = 'en') -> Dict[str, Any]:\n        \"\"\"\n        Generate video script using LLM\n        \n        Args:\n            topic: Video topic\n            duration: Target duration in seconds\n            language: Language code\n        \n        Returns:\n            Script data with scenes and narration\n        \"\"\"\n        return self.llm_service.generate_script(topic, duration, language)\n    \n    def generate_voiceover(self, script: Dict[str, Any], voice: str, language: str = 'en') -> str:\n        \"\"\"\n        Generate voiceover audio from script using Azure TTS\n        \n        Args:\n            script: Script data with narration\n            voice: Voice type (male, female, neutral)\n            language: Language code\n        \n        Returns:\n            Path to generated audio file\n        \"\"\"\n        audio_file = self.temp_dir / f\"voiceover_{os.urandom(8).hex()}.wav\"\n        \n        if not self.speech_config:\n            raise Exception(\"Azure Speech Services not configured. Please add AZURE_SPEECH_KEY and AZURE_SPEECH_REGION.\")\n        \n        try:\n            # Select voice based on language and gender\n            voice_map = {\n                'en': {'male': 'en-US-GuyNeural', 'female': 'en-US-JennyNeural', 'neutral': 'en-US-AriaNeural'},\n                'zh': {'male': 'zh-CN-YunxiNeural', 'female': 'zh-CN-XiaoxiaoNeural', 'neutral': 'zh-CN-YunyangNeural'},\n                'ar': {'male': 'ar-SA-HamedNeural', 'female': 'ar-SA-ZariyahNeural', 'neutral': 'ar-SA-HamedNeural'}\n            }\n            \n            selected_voice = voice_map.get(language, voice_map['en']).get(voice, voice_map['en']['neutral'])\n            self.speech_config.speech_synthesis_voice_name = selected_voice\n            \n            # Configure audio output\n            audio_config = speechsdk.audio.AudioOutputConfig(filename=str(audio_file))\n            synthesizer = speechsdk.SpeechSynthesizer(speech_config=self.speech_config, audio_config=audio_config)\n            \n            # Generate speech\n            narration_text = script.get('narration', '')\n            if not narration_text:\n                raise Exception(\"No narration text found in script\")\n            \n            result = synthesizer.speak_text_async(narration_text).get()\n            \n            if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n                return str(audio_file)\n            elif result.reason == speechsdk.ResultReason.Canceled:\n                cancellation = result.cancellation_details\n                # Clean up partial file\n                if audio_file.exists():\n                    audio_file.unlink()\n                raise Exception(f\"Speech synthesis canceled: {cancellation.reason}. Error: {cancellation.error_details}\")\n            else:\n                # Clean up partial file\n                if audio_file.exists():\n                    audio_file.unlink()\n                raise Exception(f\"Speech synthesis failed with reason: {result.reason}\")\n        except Exception as e:\n            # Clean up on any error\n            if audio_file.exists():\n                audio_file.unlink()\n            raise\n    \n    def search_video_clips(self, script: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search for video clips based on script scenes using Pexels API\n        \n        Args:\n            script: Script data with scenes\n        \n        Returns:\n            List of video clip metadata with download URLs\n        \"\"\"\n        clips = []\n        \n        if not self.pexels_api:\n            raise Exception(\"Pexels API not configured. Please add PEXELS_API_KEYS.\")\n        \n        for idx, scene in enumerate(script.get('scenes', [])):\n            query = scene.get('description', '')[:100]  # Limit query length\n            if not query:\n                continue\n            \n            try:\n                # Search for videos on Pexels using correct API\n                self.pexels_api.search_videos(query, page=1, results_per_page=3)\n                videos = self.pexels_api.get_entries()\n                \n                if videos and len(videos) > 0:\n                    # Try each video until we find one with valid files\n                    for video in videos:\n                        video_files = video.video_files if hasattr(video, 'video_files') else []\n                        \n                        if not video_files:\n                            continue\n                        \n                        # Find the best quality video file (prefer HD, highest bitrate)\n                        best_file = None\n                        best_score = 0\n                        \n                        for vf in video_files:\n                            width = getattr(vf, 'width', 0)\n                            quality = getattr(vf, 'quality', '')\n                            \n                            # Score: HD quality + higher resolution\n                            score = (1000 if quality == 'hd' else 0) + width\n                            \n                            if score > best_score and width >= 1280:\n                                best_file = vf\n                                best_score = score\n                        \n                        # Fallback to first available file if no HD found\n                        if not best_file and video_files:\n                            best_file = video_files[0]\n                        \n                        if best_file:\n                            clip = {\n                                'id': getattr(video, 'id', f\"clip_{idx}\"),\n                                'url': getattr(best_file, 'link', ''),\n                                'description': query,\n                                'duration': getattr(video, 'duration', 5),\n                                'width': getattr(best_file, 'width', 1920),\n                                'height': getattr(best_file, 'height', 1080),\n                                'source': 'pexels'\n                            }\n                            \n                            if clip['url']:\n                                clips.append(clip)\n                                break  # Found a good clip for this scene\n                        \n            except Exception as e:\n                print(f\"Warning: Failed to fetch clip for scene {idx}: {str(e)}\")\n                continue\n        \n        if not clips:\n            raise Exception(\"Could not find any suitable video clips for the script scenes\")\n        \n        return clips\n    \n    def compose_video(\n        self,\n        clips: List[Dict[str, Any]],\n        audio_path: str,\n        script: Dict[str, Any],\n        subtitle_position: str = 'bottom',\n        quality: str = 'basic',\n        music: bool = True\n    ) -> str:\n        \"\"\"\n        Compose final video from clips and audio using MoviePy\n        \n        Args:\n            clips: List of video clip data with URLs\n            audio_path: Path to voiceover audio file\n            script: Script data (unused for now)\n            subtitle_position: Subtitle position (unused for now)\n            quality: Video quality setting (basic, hd, premium)\n            music: Background music flag (unused for now)\n        \n        Returns:\n            Path to final video file\n        \"\"\"\n        output_file = self.output_dir / f\"video_{os.urandom(8).hex()}.mp4\"\n        downloaded_clips = []\n        \n        with ExitStack() as stack:\n            try:\n                # Step 1: Download video clips\n                for i, clip in enumerate(clips):\n                    clip_path = self.temp_dir / f\"clip_{i}_{os.urandom(4).hex()}.mp4\"\n                    try:\n                        response = requests.get(clip['url'], stream=True, timeout=30)\n                        response.raise_for_status()\n                        \n                        with open(clip_path, 'wb') as f:\n                            for chunk in response.iter_content(chunk_size=8192):\n                                f.write(chunk)\n                        \n                        downloaded_clips.append(clip_path)\n                    except Exception as e:\n                        print(f\"Warning: Failed to download clip {i}: {str(e)}\")\n                        continue\n                \n                if not downloaded_clips:\n                    raise Exception(\"Failed to download any video clips\")\n                \n                # Step 2: Load audio to get duration\n                audio_clip = stack.enter_context(AudioFileClip(audio_path))\n                total_audio_duration = audio_clip.duration\n                \n                # Step 3: Load and process video clips\n                target_resolution = (1920, 1080) if quality in ['hd', 'premium'] else (1280, 720)\n                video_clips = []\n                \n                for clip_path in downloaded_clips:\n                    try:\n                        video = stack.enter_context(VideoFileClip(str(clip_path)))\n                        # Resize to target resolution\n                        video = video.resize(target_resolution)\n                        video_clips.append(video)\n                    except Exception as e:\n                        print(f\"Warning: Failed to load clip {clip_path}: {str(e)}\")\n                        continue\n                \n                if not video_clips:\n                    raise Exception(\"Failed to load any video clips\")\n                \n                # Step 4: Adjust clip durations to match audio\n                duration_per_clip = total_audio_duration / len(video_clips)\n                adjusted_clips = []\n                \n                for video in video_clips:\n                    if video.duration > duration_per_clip:\n                        # Trim if too long\n                        adjusted = video.subclip(0, duration_per_clip)\n                    else:\n                        # Loop if too short - manually concatenate copies\n                        loops_needed = int(duration_per_clip / video.duration) + 1\n                        looped = concatenate_videoclips([video] * loops_needed)\n                        adjusted = looped.subclip(0, duration_per_clip)\n                    \n                    adjusted_clips.append(adjusted)\n                \n                # Step 5: Concatenate all clips\n                final_video = concatenate_videoclips(adjusted_clips, method=\"compose\")\n                \n                # Step 6: Add audio\n                final_video = final_video.with_audio(audio_clip)\n                \n                # Step 7: Set quality parameters\n                quality_settings = {\n                    'basic': {'bitrate': '1000k', 'audio_bitrate': '128k'},\n                    'hd': {'bitrate': '2500k', 'audio_bitrate': '192k'},\n                    'premium': {'bitrate': '5000k', 'audio_bitrate': '256k'}\n                }\n                \n                settings = quality_settings.get(quality, quality_settings['basic'])\n                \n                # Step 8: Write output file\n                final_video.write_videofile(\n                    str(output_file),\n                    codec='libx264',\n                    audio_codec='aac',\n                    bitrate=settings['bitrate'],\n                    audio_bitrate=settings['audio_bitrate'],\n                    fps=24,\n                    preset='medium',\n                    threads=2,\n                    logger=None  # Suppress verbose output\n                )\n                \n                # Clean up adjusted clips and final video\n                for clip in adjusted_clips:\n                    try:\n                        clip.close()\n                    except:\n                        pass\n                \n                try:\n                    final_video.close()\n                except:\n                    pass\n                \n                return str(output_file)\n                \n            finally:\n                # Always clean up downloaded temp files\n                for clip_path in downloaded_clips:\n                    try:\n                        clip_path.unlink()\n                    except:\n                        pass\n","size_bytes":13799},"app/utils/__init__.py":{"content":"\"\"\"\nNanoTik Utilities Package\n\"\"\"\n\nfrom .i18n import get_text, set_language, SUPPORTED_LANGUAGES\n\n__all__ = ['get_text', 'set_language', 'SUPPORTED_LANGUAGES']\n","size_bytes":160},"app/utils/i18n.py":{"content":"\"\"\"\nInternationalization utilities for multi-language support\nSupports English, Chinese (Simplified), and Arabic\n\"\"\"\n\nfrom typing import Dict, Any\n\nSUPPORTED_LANGUAGES = {\n    'en': '🇬🇧 English',\n    'zh': '🇨🇳 简体中文',\n    'ar': '🇸🇦 العربية'\n}\n\nTRANSLATIONS = {\n    'en': {\n        'app.subtitle': 'AI-Powered Video Generator with Nano Payments',\n        'language.select': 'Language',\n        'credits.balance': 'Credits',\n        'credits.name': 'credits',\n        'credits.bonus': 'bonus',\n        'credits.buy': '💰 Buy Credits',\n        'credits.purchase': 'Purchase',\n        'credits.info': '💡 Credits are used to generate videos. Different quality levels require different amounts of credits.',\n        'credits.costs': 'Credit Costs',\n        'credits.insufficient': '⚠️ Insufficient credits. Please purchase more credits to continue.',\n        'credits.buy_prompt': '👉 Use the sidebar to purchase credits with Nano cryptocurrency.',\n        'payment.processing': 'Processing payment...',\n        'payment.success': '✅ Payment successful! Credits added to your account.',\n        'payment.failed': '❌ Payment failed. Please try again.',\n        'payment.error': 'Payment error',\n        'video.generate': '🎬 Generate Video',\n        'video.topic': 'Video Topic',\n        'video.topic_placeholder': 'Enter the topic for your video...',\n        'video.topic_required': 'Please enter a video topic.',\n        'video.quality': 'Video Quality',\n        'video.duration': 'Duration (seconds)',\n        'video.advanced': '⚙️ Advanced Options',\n        'video.voice': 'Voice Type',\n        'video.music': 'Add Background Music',\n        'video.subtitle_position': 'Subtitle Position',\n        'video.create': '🚀 Create Video',\n        'video.basic': 'Basic (1 credit)',\n        'video.hd': 'HD (2 credits)',\n        'video.premium': 'Premium (3 credits)',\n        'video.generating_script': 'Generating script with AI...',\n        'video.generating_voice': 'Creating voiceover...',\n        'video.searching_clips': 'Searching for video clips...',\n        'video.composing': 'Composing final video...',\n        'video.complete': 'Video generation complete!',\n        'video.success': '🎉 Your video is ready!',\n        'video.download': '📥 Download Video',\n        'video.error': 'Video generation error',\n        'gallery.title': '🎞️ My Videos',\n        'gallery.empty': 'No videos yet. Create your first video!',\n        'gallery.created': 'Created',\n        'tabs.create': '🎬 Create',\n        'tabs.gallery': '🎞️ Gallery',\n        'tabs.about': 'ℹ️ About',\n        'about.content': '''\n## About NanoTik\n\nNanoTik is an AI-powered video generator that uses cutting-edge technology to create professional videos from simple text prompts.\n\n### How It Works\n1. **Choose a Topic**: Tell us what your video should be about\n2. **AI Script Generation**: Our AI creates an engaging script\n3. **Automated Production**: We generate voiceovers, find clips, and compose your video\n4. **Download & Share**: Get your professional video in minutes\n        ''',\n        'about.features': '✨ Features',\n        'about.feature1': '🤖 AI-powered script generation',\n        'about.feature2': '💰 Instant Nano cryptocurrency payments',\n        'about.feature3': '🌍 Multi-language support (English, Chinese, Arabic)',\n        'about.feature4': '📱 Responsive design for all devices',\n        'about.feature5': '🎨 Professional quality output',\n        'footer.text': '© 2025 NanoTik - Built with ❤️ using Streamlit'\n    },\n    'zh': {\n        'app.subtitle': '基于AI的视频生成器，支持Nano支付',\n        'language.select': '语言',\n        'credits.balance': '积分',\n        'credits.name': '积分',\n        'credits.bonus': '奖励',\n        'credits.buy': '💰 购买积分',\n        'credits.purchase': '购买',\n        'credits.info': '💡 积分用于生成视频。不同的质量级别需要不同数量的积分。',\n        'credits.costs': '积分消费',\n        'credits.insufficient': '⚠️ 积分不足。请购买更多积分以继续。',\n        'credits.buy_prompt': '👉 使用侧边栏通过Nano加密货币购买积分。',\n        'payment.processing': '正在处理付款...',\n        'payment.success': '✅ 付款成功！积分已添加到您的账户。',\n        'payment.failed': '❌ 付款失败。请重试。',\n        'payment.error': '付款错误',\n        'video.generate': '🎬 生成视频',\n        'video.topic': '视频主题',\n        'video.topic_placeholder': '输入您的视频主题...',\n        'video.topic_required': '请输入视频主题。',\n        'video.quality': '视频质量',\n        'video.duration': '时长（秒）',\n        'video.advanced': '⚙️ 高级选项',\n        'video.voice': '语音类型',\n        'video.music': '添加背景音乐',\n        'video.subtitle_position': '字幕位置',\n        'video.create': '🚀 创建视频',\n        'video.basic': '基础（1积分）',\n        'video.hd': '高清（2积分）',\n        'video.premium': '专业版（3积分）',\n        'video.generating_script': '正在使用AI生成脚本...',\n        'video.generating_voice': '正在创建配音...',\n        'video.searching_clips': '正在搜索视频片段...',\n        'video.composing': '正在合成最终视频...',\n        'video.complete': '视频生成完成！',\n        'video.success': '🎉 您的视频已准备就绪！',\n        'video.download': '📥 下载视频',\n        'video.error': '视频生成错误',\n        'gallery.title': '🎞️ 我的视频',\n        'gallery.empty': '还没有视频。创建您的第一个视频！',\n        'gallery.created': '创建于',\n        'tabs.create': '🎬 创建',\n        'tabs.gallery': '🎞️ 画廊',\n        'tabs.about': 'ℹ️ 关于',\n        'about.content': '''\n## 关于NanoTik\n\nNanoTik是一款由AI驱动的视频生成器，使用尖端技术从简单的文本提示创建专业视频。\n\n### 工作原理\n1. **选择主题**：告诉我们您的视频主题\n2. **AI脚本生成**：我们的AI创建引人入胜的脚本\n3. **自动制作**：我们生成配音、查找片段并合成您的视频\n4. **下载和分享**：几分钟内获得专业视频\n        ''',\n        'about.features': '✨ 特点',\n        'about.feature1': '🤖 AI驱动的脚本生成',\n        'about.feature2': '💰 即时Nano加密货币支付',\n        'about.feature3': '🌍 多语言支持（英语、中文、阿拉伯语）',\n        'about.feature4': '📱 适用于所有设备的响应式设计',\n        'about.feature5': '🎨 专业质量输出',\n        'footer.text': '© 2025 NanoTik - 使用Streamlit构建，充满❤️'\n    },\n    'ar': {\n        'app.subtitle': 'مولد فيديو مدعوم بالذكاء الاصطناعي مع مدفوعات نانو',\n        'language.select': 'اللغة',\n        'credits.balance': 'الأرصدة',\n        'credits.name': 'أرصدة',\n        'credits.bonus': 'مكافأة',\n        'credits.buy': '💰 شراء الأرصدة',\n        'credits.purchase': 'شراء',\n        'credits.info': '💡 تُستخدم الأرصدة لإنشاء مقاطع الفيديو. تتطلب مستويات الجودة المختلفة كميات مختلفة من الأرصدة.',\n        'credits.costs': 'تكاليف الأرصدة',\n        'credits.insufficient': '⚠️ أرصدة غير كافية. يرجى شراء المزيد من الأرصدة للمتابعة.',\n        'credits.buy_prompt': '👉 استخدم الشريط الجانبي لشراء الأرصدة باستخدام عملة نانو المشفرة.',\n        'payment.processing': 'جاري معالجة الدفع...',\n        'payment.success': '✅ تم الدفع بنجاح! تمت إضافة الأرصدة إلى حسابك.',\n        'payment.failed': '❌ فشل الدفع. يرجى المحاولة مرة أخرى.',\n        'payment.error': 'خطأ في الدفع',\n        'video.generate': '🎬 إنشاء فيديو',\n        'video.topic': 'موضوع الفيديو',\n        'video.topic_placeholder': 'أدخل موضوع الفيديو الخاص بك...',\n        'video.topic_required': 'يرجى إدخال موضوع الفيديو.',\n        'video.quality': 'جودة الفيديو',\n        'video.duration': 'المدة (بالثواني)',\n        'video.advanced': '⚙️ خيارات متقدمة',\n        'video.voice': 'نوع الصوت',\n        'video.music': 'إضافة موسيقى خلفية',\n        'video.subtitle_position': 'موضع الترجمة',\n        'video.create': '🚀 إنشاء فيديو',\n        'video.basic': 'أساسي (رصيد واحد)',\n        'video.hd': 'عالي الدقة (رصيدان)',\n        'video.premium': 'متميز (3 أرصدة)',\n        'video.generating_script': 'جاري إنشاء النص باستخدام الذكاء الاصطناعي...',\n        'video.generating_voice': 'جاري إنشاء التعليق الصوتي...',\n        'video.searching_clips': 'جاري البحث عن مقاطع الفيديو...',\n        'video.composing': 'جاري تركيب الفيديو النهائي...',\n        'video.complete': 'اكتمل إنشاء الفيديو!',\n        'video.success': '🎉 الفيديو الخاص بك جاهز!',\n        'video.download': '📥 تحميل الفيديو',\n        'video.error': 'خطأ في إنشاء الفيديو',\n        'gallery.title': '🎞️ مقاطع الفيديو الخاصة بي',\n        'gallery.empty': 'لا توجد مقاطع فيديو بعد. أنشئ أول فيديو لك!',\n        'gallery.created': 'تم الإنشاء',\n        'tabs.create': '🎬 إنشاء',\n        'tabs.gallery': '🎞️ المعرض',\n        'tabs.about': 'ℹ️ حول',\n        'about.content': '''\n## حول NanoTik\n\nNanoTik هو مولد فيديو مدعوم بالذكاء الاصطناعي يستخدم أحدث التقنيات لإنشاء مقاطع فيديو احترافية من مطالبات نصية بسيطة.\n\n### كيف يعمل\n1. **اختر موضوعًا**: أخبرنا عما يجب أن يكون عليه الفيديو الخاص بك\n2. **إنشاء النص بالذكاء الاصطناعي**: ينشئ الذكاء الاصطناعي لدينا نصًا جذابًا\n3. **الإنتاج الآلي**: ننشئ التعليقات الصوتية ونجد المقاطع ونركب الفيديو الخاص بك\n4. **التنزيل والمشاركة**: احصل على الفيديو الاحترافي الخاص بك في دقائق\n        ''',\n        'about.features': '✨ الميزات',\n        'about.feature1': '🤖 إنشاء النصوص بالذكاء الاصطناعي',\n        'about.feature2': '💰 مدفوعات فورية بعملة نانو المشفرة',\n        'about.feature3': '🌍 دعم متعدد اللغات (الإنجليزية، الصينية، العربية)',\n        'about.feature4': '📱 تصميم متجاوب لجميع الأجهزة',\n        'about.feature5': '🎨 إخراج بجودة احترافية',\n        'footer.text': '© 2025 NanoTik - بُني بـ❤️ باستخدام Streamlit'\n    }\n}\n\n_current_language = 'en'\n\n\ndef get_text(key: str, language: str | None = None) -> str:\n    \"\"\"\n    Get translated text for a given key\n    \n    Args:\n        key: Translation key in dot notation (e.g., 'app.subtitle')\n        language: Language code (defaults to current language)\n    \n    Returns:\n        Translated text or the key if not found\n    \"\"\"\n    lang = language if language is not None else _current_language\n    \n    if lang not in TRANSLATIONS:\n        lang = 'en'\n    \n    return TRANSLATIONS[lang].get(key, key)\n\n\ndef set_language(language: str):\n    \"\"\"Set the current application language\"\"\"\n    global _current_language\n    if language in SUPPORTED_LANGUAGES:\n        _current_language = language\n","size_bytes":12062}},"version":1}